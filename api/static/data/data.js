let data = [
    {
        "id":0,
        "type": "lesson",
        "title": "الدرس الاول",
        "video": "https://res.cloudinary.com/dtxava86t/video/upload/v1683583188/video/lesson1.mp4",
        "sub-title": "ما هي معالجة اللغة الطبيعية NLP ؟",
        "desc": `
            تعتبر معالجة اللغات الطبيعية من المواضيع المثيرة للاهتمام في عصر أصبحت به التكنولوجيا شريكة البشر في كل المجالات تتم معالجة اللغات الطبيعية من خلال مراحل متكاملة مع بعضها للوصول إلى الهدف المطلوب.

            يفهم الكثير من المستخدمين للحاسبات وتكنولوجيا المعلومات العلاقة بين الحاسب واللغة على أن الحاسب قدم إمكانات كبرى اعانت – ولا تزال على دراسة اللغات الإنسانية وتحليلها وتبسيطها وتيسير تعليمها، أما اللغة فكانت ولاتزال هى الوعاء أو الوسيط الذي يتم من خلاله التفاعل بين الإنسان مع الحاسب يبدو أن العلاقة ليست كذلك بالضبط فالخبراء والعلماء والمتخصصون ينظرون إليها نظرة أخرى واضحة الاختلاف، تنطوي على الكثير من التعقيدات والجوانب الغامضة وغير المفهومة بالنسبة للكثيرين حيث تعتبر لغة الإنسان معقدة وغامضة وغير منظمة ومتنوعة، وهناك أكثر من ٦٥٠٠ لغة في العالم، كل منها لها قواعدها النحوية والدلالية، وحتى البشر يكافحون لفهم اللغة، لذا، لكي تفهم الآلات اللغات الطبيعية يجب أولا أن تتحول إلى شيء يمكنها تفسيره في معالجة اللغة الطبيعية، يعد بناء الجملة والتحليل الدلالي مفتاحاً لفهم البنية النحوية للنص وتحديد كيفية ارتباط الكلمات ببعضها البعض في سياق معين، لكن تحويل النص إلى شيء يمكن للآلات معالجته لا يزال معقدا، حيث يحتاج علماء البيانات إلى تعليم أدوات معالجة اللغات الطبيعية للنظر إلى ما وراء التعريفات وترتيب الكلمات، ذلك لفهم السياق والغموض في الكلمات والمفاهيم المعقدة الأخرى المرتبطة باللغة البشرية.

            تمتلئ الشركات ببيانات غير منظمة، ومن المستحيل عليها تحليل كل هذه البيانات ومعالجتها دون مساعدة. تهتم المعالجة الآلية للغات الطبيعية بدراسة اللسان البشري ومحاولة الاستفادة من العلوم الأخرى بغرض حوسبة اللغة و لا يخص الأمر لغة معينة. لم يعد يهتم البحث اللساني بالطرق التي بموجبها تتكون الجمل في لغة من اللغات فقط، وإنما أصبح موضوع اللسانيات يتسع ليشمل التعرف على الكيفية التي يشتغل بها الدماغ البشري، أي تحديد الآلة اللغوية ذاتها، في محاولة التعرف على سر تكوينها وطريقة اشتغالها لدى الإنسان عامة. ولعل هذا هو الإشكال الذي يثار والسر الذي استعصى فهمه حتى على العلوم الدقيقة التي تمتلك من الأدوات الإجرائية ما يمكنها من ذلك.

            علاقة اللغة بالحاسب بأنها علاقة منفعة متبادلة، فعلى جبهة اللغة يستخدم الحاسب حاليا لإقامة النماذج اللغوية وتحليل الفروع اللغوية المختلفة، ومن أمثلة تطبيقات الحاسب في مجال اللغويات الصرف الحاسوبي والنحو الحاسوبي والدلالة الحاسوبية والمعجمية الحاسوبية وعلم النفس اللغوى الحاسوبي. وفي المقابل اقتبس علماء الحاسب في تطويرهم للغات البرمجة الكثير من أسس اللغات الطبيعية ويسعون بخطى حثيثة إلى التقريب بين هذه اللغات الاصطناعية واللغات الطبيعية بهدف تسهيل التعامل مع الحاسب دون وسيط برمجي، فالهدف الأسمى لبرمجة الحاسب هو أن يتعامل الفرد معه مباشرة بلغته الطبيعية بدلا من اللغات الاصطناعية. نخلص منها إلى أن المعالجة الآلية للغة هى جهود تحاول إزالة الحواجز ما بين اللغة التي يستخدمها الإنسان العادى فى ظروفه الطبيعية، والحاسب كآلة ذات قدرات عالية في فهرسة وتخزين ومعالجة واستدعاء البيانات والمعلومات، بما يجعل الإنسان قادر على استثمار أقصى طاقات وإمكانات الحاسب بسهولة ويسر وعبر لغة التعامل الطبيعية، وبما يجعل الحاسب قادر على أن يفهم لغة الإنسان العادية الطبيعية على مستوى الكلمة والجملة والمعنى وينفذ ما يريده الإنسان عبر هذا الفهم.

            تتجلى أهمية برمجيات معالجة اللغات الطبيعية Natural Languages Processing) (NLP) في جعل الحوار بين الإنسان والآلة ممكنا بلغة أقرب ما تكون إلى اللغات الطبيعية التي يستخدمها في الحوار مع أقرانه، وذلك باستخدام الذكاء الاصطناعي فاللغة . منظومة من الرموز والمعاني والأصوات والقواعد التي يؤدي اندماجها إلى التخاطب مع الإنسان حيث يستخدم تعبير اللغات الطبيعية للإشارة إلى اللغات الإنسانية؛ كاللغة العربية والإنكليزية والروسية وغيرها لتمييزها من اللغات غير الطبيعية كلغات برمجة الكمبيوتر والشفرات السرية وغيرها. تستخدم هذه اللغات للتفاهم والاتصال سواء بين الإنسان والإنسان أو بين الإنسان والآلة، كما أن لكل منها مفرداتها ونحوها وقواعدها اللغوية التي تحدد كيفية بناء الجمل ومعناها الدلالي. يهدف هذا المجال إلى تأمين التخاطب المباشر بين الإنسان والكمبيوتر؛ كتابة أو كلاما بلغة الإنسان الطبيعية، بدلا من لغة البرمجة الجامدة والصعبة ،الفهم، وهذا يسهل على الإنسان جميع العادي استثمار الكمبيوتر تم إنجاز تقدم ملحوظ في مجال معالجة اللغات الطبيعية في الفترة الأخيرة، حيث تستعمل تقانات معالجة اللغات الطبيعية في الكثير من المجالات، مثل نظم الاستفادة من بنوك المعلومات التي تخزن الموسوعات و الكتب القيمة ونظم الإجابة عن الأسئلة، ونظم فهم الكلام وتوليده، ونظم قراءة النصوص وفهمها، ونظم تأليف النصوص، وغير ذلك.

            المعالجة الآلية للغات الإنسانية Natural Language Processing هي مجال فرعي يتبع الذكاء الاصطناعي واللغويات الحاسوبية ، ويعنى بدراسة مشكلات التوليد والفهم الآلي للغات الإنسانية الطبيعية، وتهدف أنظمة توليد اللغات الطبيعية إلى تحويل البيانات والمعلومات المخزنة في قواعد بيانات الحاسب إلى لغة بشرية تبدو طبيعية، أما أنظمة فهم اللغات الطبيعية فتحويل عينات ونماذج اللغات الإنسانية إلى تمثيل شكلى يسهل على برامج الحاسب تطويعه والتعامل معه.

            تعريف معالجة اللغات الطبيعيه NLP :

            معالجة اللغة الطبيعية Natural Language Processing أو اختصارا NLP هي العلم الذي يجمع بين اللغة وعدد من مجالات علم الحاسب الآلي، مثل تعلم الآلة Machine Learning التعلم العميق Deep Learning الشبكات العصبية الصناعية Artificial Natural Networks

            تعد معالجة اللغة الطبيعية أيضا مجال من أكثر مجالات الذكاء الاصطناعي Artificial Intelligence أهمية وصعوبة في نفس الوقت، فهي أساسية لتحسين أجهزة وآلالات الذكاء الاصطناعية، ولكن لديها أيضا العديد من التحديات التي سنناقشها فيما بعد في هذا الكتاب.

            ومعالجة اللغة الطبيعية ليست علمًا حديثا بل أن أصولها النظرية ترجع إلى مئات الأعوام وبداية وجودها الفعلي تعود إلى ٦٠ عام من اليوم، وهي تحاول دمج خوارزميات الحوسبة اللغوية computational linguistics بالإضافة إلى الخوارزميات الإحصائية الخاصة بتعلم الآلة والتعلم العميق، وذلك لجعل الآلة قادرة على فهم اللغة ومعانيها المعقدة.

            تستخدم هذه التقنية في العديد من الأشياء التي نستخدمها يوميًا، بدءًا من محركات البحث Search Engines ، وأنظمة الكتابة، وتصحيح الأخطاء في لوحات كتابة الهواتف المحمولة، وحتى في البحث الطبي ومجالات المال والأعمال والبحث الأكاديمي، وسوف نتحدث عن العديد من استخدامات الـ NLP

            والمقصود باللغة الطبيعية في الـ NLP هي اللغات البشرية كالعربية والإنجليزية التي نشأت وتطورت بدون تخطيط أو قواعد موضوعة مسبقا، ولديها العديد من اللهجات المحلية و اللهجات العامية المختلفة، كما أنها تتطور تلقائيًا، ولذا تتطلب تحديثا في استخراج قواعدها مع مرور الوقت.

            أما اللغة الاصطناعية Artificial Language ، فهي مثل لغات البرمجة ك Python وغيرها، والتي وضع الإنسان قواعدها ،ومصطلحاتها وهي عادة لا تستخدم بين البشر وبعضهم البعض، وإنما بين البشر والحواسيب لكونها واضحة ومباشرة، ولا تحتوي على أي غموض أو لبس لغوي أو احتمال لوجود معنى آخر لأوامرها

            يتم تعريف معالجة اللغات الطبيعية علي النحو التالي: عبارة عن تقنية تعلم الآلة تمكن أجهزة الكمبيوتر من تفسير اللغة البشرية ومعالجتها وفهمها.

            معالجة اللغة الطبيعية : جعل الآلة قادرة على فهم اللغة البشرية وتوليدها، سواء اللغة المكتوبة أو اللغة المسموعة، كما تحاول تحسين التواصل الذي يتم بين الإنسان والآلة، وجعله يشابه ما يحدث بين الإنسان والإنسان.

            معالجة اللغات الطبيعية (NLP) عبارة عن تقنية تعلم الآلة تمكن أجهزة الكمبيوتر من تفسير اللغة البشرية ومعالجتها وفهمها. تمتلك المؤسسات اليوم كميات كبيرة من البيانات الصوتية والنصية من قنوات اتصال مختلفة مثل رسائل البريد الإلكتروني، والرسائل النصية وموجزات الأخبار على وسائل التواصل الاجتماعي والفيديوهات، والمقاطع الصوتية والمزيد وهي تستخدم برمجيات معالجة اللغات الطبيعية (NLP) لمعالجة هذه البيانات تلقائيا وتحليل النية أو المشاعر في الرسالة والاستجابة في الوقت الفعلي للتواصل البشري.

            أهداف معالجة اللغات الطبيعية :-

            المعالجة الآلية للغة ظهرت في الأساس من أجل تطوير وإنشاء وصياغة تطبيقات الترجمة الآلية سواء كانت مكتوبة أو منطوقة، والترجمة الآلية هى الوسيلة الوحيدة التي تستطيع بها الأمم مواكبة الانفجار المعرفي والمعلوماتي في عصر الإنترنت الساحق وفضاءاتها الإلكترونية الواسعة. حيث لا يستطيع أى مجتمع أو أمة مهما كانت أن تعيش بمعزل عن هذه الثورة المعرفية أمام اكتساح اللغة الإنجليزية لكل المراجع المعرفية والمعلوماتية في فضاء الإنترنت وانتشارها بشكل يهدد بانسحاق كل الأمم واللغات التى لا تستخدم تكنولوجيا المعلومات والحاسب في اللحاق بعصر المعلومات.

            ومن أحد أهداف وتطبيقات المعالجة الآلية للغة مساعدة المستخدم والإدارى والعالم والمسئول الحكومي فى عصر فيض وطغيان المعلومات على الوصول للمعلومات التي يريدها بسهولة وسرعة من خلال التلخيص الالى والتحليل الآلى للنصوص بالإضافة إلى البحث الذكي عن المعلومات فى شبكة الإنترنت فى أجيالها الجديدة التى تعرف باسم الويب الدلالية.

            ويؤدى التطور فى تطبيقات المعالجة الآلية للغة إلى تسهيل حصول المرء على المعلومة في أي مكان وأى وقت، ومن أمثلة السيناريوهات المستقبلية لتوضيح هذا الأمر تخيل نفسك أنك تقود سيارتك في رحلة لقضاء عطلة الصيف في الساحل الشمالي، وكنت تريد متابعة أسهم شركتك في البورصة، فماذا ستفعل؟ ستخاطب حاسب السيارة قائلا أريد تقريرا تفصيليا عن حالة أسهم شركة ما فى البورصة خلال اليومين الماضيين؟ ماذا الذى سيحدث؟ سيقوم حاسب السيارة بتحويل عبارتك الصوتية إلى أوامر بحث نصية ويرسلها إلى شبكة الإنترنت عبر التقنيات اللاسلكية المتقدمة، وستقوم شبكة الإنترنت بفحص أسهم شركتك خلال اليومين السابقين وترسلها إلى حاسب السيارة مرة أخرى الذى يحول المعلومات النصية إلى كلام منطوق تسمعه بأذنيك لأنك بطبيعة الحال تركز في القيادة.
            ويمكن اختصار أهداف المعالجة الآلية للغات الإنسانية بصفة عامة في ثلاثة أهداف هي:

            １-	تواصل أفضل مع الحاسب :-

            تمكن وسائل البحث باللغة العادية الإنسان من التواصل مع الحاسب بالفرنسية أو الألمانية أو العربية أو أى لغة أخرى فالتواصل مع الحاسب باللغة المنطوقة سيكون له تأثير كبير على بيئة العمل، وستنبثق مجالات جديدة واسعة أمام تكنولوجيا المعلومات.

            ２-	 تواصل أفضل بين البشر :-

            من الأهداف الأولى التى ظهرت من أجلها علوم اللغويات الحاسوبية والمعالجة الآلية الترجمة الآلية بين اللغات الحية من أجل مزيد من التواصل بين البشر ، ورغم أن تجربة الفشل المريرة قد جعلت العلماء يدركون أنهم بعيدون جدا عن تحقيق هذا الهدف الطموح في ترجمة النصوص غير المحدودة، تمكن علماء اللغويات الحاسوبية من إنشاء برمجيات تبسط عمل المترجم البشرى وتحسن من إنتاجيته إلى حد كبير، وتقدم الترجمة الآلية الركيكة أو الحرفية مساعدة كبيرة لباحثي المعلومات الذين يبحثون عن المدلول أو المعنى في كميات كبيرة من النصوص باللغات الأجنبية.

            ３-	الوصول الفعال للمعلومات :-

            تصفح المعلومات على الويب والتنقل بينها وفلترتها ومعالجتها يتطلب تطوير برمجيات يمكنها الوصول إلى المعلومات فى المستندات والوثائق وصفحات الويب، وهكذا فإن تكنولوجيا اللغات الإنسانية لإدارة المحتوى شرط ضرورى لتحويل ثروة المعلومات الرقمية إلى معرفة جماعية، وتعدد لغات المحتوى على الويب يمثل تحديا إضافيا لتكنولوجيا اللغة، لأنه لا يمكن السيطرة على الويب العالمية إلا بمساعدة الأدوات متعددة اللغات لفهرسة وتصفح الويب، وستذلل أنظمة إدارة المعرفة والمعلومات متعددة اللغات عقبات اللغة أمام التجارة الإلكترونية والتعليم عن بعد.

            أسباب الاهتمام بمعالجة اللغات الطبيعية :-

            -	التطور الهائل في علوم اللغويات وخضوعها للمعالجة الرياضية والمنطقية. 
            -	ظهور النظم الآلية الخبيرة التى تستطيع تشخيص الأمراض وتقديم الاستشارات الفنية والقانونية والنظم الآلية للتعليم الذاتي التي تتطلب قدرة على الحوار مع المستخدم البشرى بلغة سهلة مثل لغته الطبيعية.
            -	  انتشار الحاسب كوسيلة للتعليم والتعلم، وخاصة تعليم وتعلم اللغات.
            -	التقدم العلمي في تقنيات الحاسب ومكوناته ولغات برمجته وأساليب الذكاء الصناعي. 
            - الاستعانة باللغات البشرية في تصميم لغات برمجة راقية تتسم بالقوة والمرونة.
            -	يتطلب الانفجار المعرفي استحداث وسائل آلية لتنظيم هذا الكم المتزايد من المعلومات وتحسين كفاءة تخزينها واسترجاعها وتوظيفها.
            -	انتشار الحاسبات الشخصية والمنزلية بشكل يحتم ضرورة التعامل معها بلغة طبيعية .
            -	 بفضل الحاسبات السوبر أمكن تطوير نظم لمعالجة اللغة آليا في حدود الجدوى الاقتصادية والفنية لهذه النظم

            ما سبب أهمية معالجة اللغات الطبيعية (NLP) ؟

            تعد معالجة اللغة الطبيعية أمرًا بالغ الأهمية لتحليل بيانات النص والكلام تحليلا كاملا وبكفاءة. يمكن أن تعمل من خلال الاختلافات في اللهجات واللغة العامية والأخطاء النحوية المعتادة في المحادثات اليومية تستخدمها الشركات في العديد من المهام الآلية، مثل:

            . معالجة المستندات الكبيرة وتحليلها وأرشفتها
            . تحليل ملاحظات العملاء أو تسجيلات مراكز الاتصال
            . تشغيل برامج الدردشة الآلية الخاصة بخدمة العملاء الآلية
            . الإجابة على أسئلة من وماذا ومتى وأين
            . تصنيف النص واستخراجه

            أنواع معالجة اللغة الطبيعية NLP :-

            هناك العشرات من أنواع وتقنيات Techniques معالجة اللغات الطبيعية التي لها المئات من الاستخدامات والتطبيقات التي تسهل علينا حياتنا كل يوم.

            وإليك نبذة عن النوعين الأكثر أهمية لمعالجة اللغة الطبيعية NLP :

            في هذا الكتاب سوف نتطرق إلى أهم التقنيات الخاصة بمعالجة اللغات الطبيعية، ولكن قبل ذلك علينا التوضيح بأنه يمكن تقسيم هذه الأنواع والتقنيات إلى قسمين كبيرين، هما:
            فهم اللغة الطبيعية Natural Language Understanding أو NLU

            هذا الجزء يتعلق بالتعامل مع اللغة الطبيعية وفهمها بعد تقديمها كمدخلات للحاسوب أو الآلة سواء كانت هذه اللغة مقدمة على هيئة نص أو صوت، فالهدف هنا هو جعل الآلة تفهم اللغة الطبيعية.

            توليد اللغة الطبيعية Natural Language Generation أو NLG

            توليد اللغة الطبيعية هي التقنية التي تتيح للالة بأن تستطيع توليد محتوى سواء نصي أو صوتي يشابه هذا الذي قد يولده الإنسان العادي، أي أنه في هذه التقنية تتعامل الآلة مع اللغة على أنها مخرجات لا مدخلات.

            التطبيقات المتعددة لمعالجة اللغة الطبيعية :-

            １-	التعرف على الكلام Speech recognition

            يتم استخدام هذه التقنية على نطاق واسع هذه الأيام، وتستخدم من أجل تحويل البيانات الصوتية إلى بيانات نصية، وهذا بهدف إعطاء الأوامر الصوتية أو طرح بعض الأسئلة بشكل صوتي بدون الحاجة إلى الكتابة. 
            تواجه هذه التقنية العديد من التحديات مثل تعدد اللهجات والنطق غير الصحيح، والكلمات المتشابهة، والأخطاء اللغوية، وغيرها الكثير، ولكن على الرغم من هذا فإننا نشهد تطورا ملحوظا في تطبيقاتها Siri Alexa

            قد تستخدم تقنية التعرف على الكلام Speech recognition في أنظمة المساعدة الافتراضية وفي خدمة العملاء والاستجابة إلى شكواهم وعشرات الاستخدامات غيرها.

            في هذا التطبيق أيضا لا يتعرف على نص مكتوب ويحوله إلى كلام منطوق، بل يستمع إلى صوت مسموع ويقوم بالتعرف عليه وتحديد هوية صاحبه، من خلال تحويل الصوت إلى رموز تفهمها الآلة وتتعرف عليه، وهو يختلف كذلك عن مصطلح التعرف على الصوت Voice Recognition ويقصد به التعرف على صوت المتحدث نفسه وليس الكلام الذي يقوله. ومن تطبيقات فهم الكلام الاتصالات الصوتية وتوجيه المكالمات والتحكم في الأجهزة المنزلية والبحث في المحتوى بالصوت وإدخال البيانات البسيطة وإعداد المستندات المنظمة وتحويل الكلام إلى نص مكتوب وفى كابينات القيادة بالطائرات

            و من تطبيقات فهم الكلام المنطوق استخدامها في القيادة الآلية للطائرات العسكرية والتحكم في أجهزتها وخاصة في بريطانيا وفرنسا والولايات المتحدة وفى طائرات الهليكوبتر حيث مشكلة الضوضاء الخلفية بسبب صوت المروحة والهواء وفى إدارة المعارك حيث تتطلب مراكز القيادة الوصول السريع لقواعد بيانات المعلومات المتغيرة بسرعة كما تستخدم في تدريب مراقبي حركة المرور الجوي، بجانب استخدامها في مجال الاتصالات التليفونية والعاب الحاسب والمحاكاة، ولم يتم تثبيت هذه التكنولوجيا في الأجهزة المحمولة لأنها تتطلب قوة معالجة هائلة، وهذه التكنولوجيا مفيدة للغاية لمن لا يستطيعون تحريك أيديهم، مما يتطلب وسيلة بديلة لإدخال المعلومات في الحاسب والتحكم في وظائفه. 
            ２-	 تصنيف النصوص Text Classification

            تصنيف النصوص هو واحد من أكثر تقنيات معالجة اللغة الطبيعية استخدامًا وتشعبا في وقتنا هذا، فهذه التقنية قد تم تطويرها منذ بدايات نشأة الـ NLP ، بجانب هذا فهي الأكثر انتشارًا واستخداما في حياتنا اليومية، على سبيل المثال في تصنيف رسائل البريد الإلكتروني الخاصة بنا

            من خلال هذه التقنية نستطيع التعامل مع النصوص بمختلف أشكالها وأغراضها، ومن ثم نقوم بتوزيعها على تصنيفات مختلفة بناءًا على محتواها، ومن أبرز التقنيات الفرعية لتصنيف

            النصوص: Text Classification

            أ‌)	تصنيف الموضوعات Topic Classification

            باستخدام هذه التقنية تتم معالجة النصوص المختلفة ومن ثم تحديد موضوعاتها الأساسية، ومن ثم ترتيبها حسب المواضيع الخاصة بها ووضعها في التصنيفات المناسبة لها.

            تساعد هذه التقنية عند التعامل مع النصوص الكثيرة التي يصعب على الإنسان قراءتها، ووضعها في تصنيفات محددة سواء لصعوبتها أو لأخذها وقنا وجهدًا كبيرًا.

            كما تقوم العديد من الشركات باستخدام هذه التقنية في إدارة مشاكل العملاء خاصتها، حيث تمرر شكوى العملاء على مصنف ليضعها في تصنيفات محددة حسب النصوص بداخلها.

            (ب) تحديد النية Intent Detection

            في هذه التقنية تقوم خوارزميات الذكاء الاصطناعي بالتعرف على الغايات والأهداف والنية من وراء النصوص أو الحديث، ولذا هذه التقنية تساعد العديد من الشركات على تحسين وإدارة أقسام كخدمة العملاء أو المبيعات بداخلها.

            (ج )الإسناد إلى الكاتب الحقيقي Authorship Attribution

            هذه التقنية مثيرة للغاية إذ أنها تتعامل مع الأعمال الإبداعية التي تثير الجدل حول مؤلفيها حيث من خلال تغذية الخوارزمية بالأعمال المختلفة للمؤلفين موضع الشك، ومن ثم تغذيتها بالعمل محل الجدال، تستطيع أن تنسب العمل لمؤلفه الحقيقي.

        `,
    },
    {
        "id":1,
        "type": "lesson",
        "title": "الدرس الثانى",
        "video": "https://res.cloudinary.com/dtxava86t/video/upload/v1683583188/video/lesson2.mp4",
        "sub-title": "استخلاص النصوص Text Extraction",
        "desc": `
            تقنية أخرى مهمة من تقنيات معالجة اللغة الطبيعية NLP هي استخلاص النصوص Text Extraction، وهي تقنية تساعد على توفير الكثير من الوقت والجهد عند الحاجة إلى البحث عن معلومات أو أجزاء محددة من النصوص بداخل كتب أو محتوى كبير للغاية وواسع.

            وهناك العديد من الخوارزميات والتقنيات المهمة التي تندرج تحت التقنية الكبرى لاستخلاص النصوص:

            (1)	استخلاص الكلمات المفتاحية Keyword Extraction

            تستطيع هذه التقنية بشكل أتوماتيكي أن تقوم باستخلاص أهم الكلمات المفتاحية والتعبيرات في نص أو مجموعة من النصوص، ويتم استخدام هذه التقنية بكثرة في محركات البحث Search Engines 

                (ب )استخلاص الأسماء ذات الدلالات Named Entity Recognition أو NER

            هذه التقنية مهمة للغاية إذ أنها تجعل الآلة قادرة على التجاوب بشكل أفضل مع اللغة الطبيعية حيث إنها تستطيع استخلاص الكلمات المقصود بها دلالات أخرى، مثل أن تكون اسم لشخص مشهور، اسم لفيلم أو مسلسل أو حتى اسم مكان.
            ４-	 الترجمة الآلية Machine Translation

            وتعنى استخدام برمجيات الحاسب في ترجمة النصوص أو الكلام من لغة إنسانية لأخرى. وفي مستواها الأساسي، تعمل برامج الترجمة الآلية على استبدال الكلمات باللغة المترجم منها بالكلمات المقابلة لها فى اللغة المترجم إليها من الممكن استخدام تقنيات الميكانزمات في إجراء عمليات ترجمة أكثر تعقيدا حيث تساهم الميكانزمات والذخائر اللغوية في التعامل مع الفروق في البنية اللغوية والتعرف على العبارات وترجمة المصطلحات بالإضافة إلى عزل الحالات الشاذة.

            تتيح برمجيات الترجمة الآلية الحالية تخصيص الترجمة حسب المجال أو المهنة، حيث يتم تحسين الترجمة النهائية من خلال حصر نطاق الاستبدالات المسموح بها، وهذا الأسلوب فعال للغاية خاصة في المجالات التى تستخدم فيها اللغة الرسمية أو الاصطلاحية، وبصفة عامة تتيح الترجمة الآلية نتائج أفضل فى النصوص الحكومية والقانونية التى تعتمد على قوالب من الجمل والعبارات بعكس النصوص العامة والمحادثات، حيث ما زالت نظم الترجمة الآلية في حاجة إلى مزيد من التطوير للوصول إلى جودة معقولة.

            ومما لا شك فيه أن الترجمة الآلية بصفة عامة وصلت إلى مستوى متقدم جدا، ونجحت في مساعدة المترجم البشرى على تحسين عمله بل وتفوقت عليه في أحيان قليلة، غير أنها في مجملها لم تستطع أن تتغلب على المترجم البشرى فى هذا المضمار، خاصة في ترجمة الحوارات والمحادثات ويزيد الأمر صعوبة لو كانت هذه الحوارات باللغة العامية أو اللغة غير الرسمية.

            وتستخدم الترجمة الآلية طريقة تعتمد على القواعد اللغوية التى تعنى ترجمة الكلمات بطريقة لغوية، حيث يتم استبدال الكلمات المناسبة فى اللغة الهدف بالكلمات المقابلة لها في اللغة المصدر، وهناك بعض الآراء التى ترى أنه لن يكتب للترجمة الآلية تحقيق النجاح ما لم تحل مشكلة فهم اللغات الطبيعية أولا.
            وتوجد عدة طرق للترجمة الآلية هي الترجمة المعتمدة على القواعد أو المعتمدة على الإحصاء.

            1-	الترجمة المعتمدة على القواعد

            تقوم لوغاريتمات الترجمة المعتمدة على القواعد بإعراب النص وإنشاء تمثيل وسيط رمزي يتم منه توليد النص باللغة الهدف، ووفقا لطبيعة التمثيل الرمزي، يوصف منهج الترجمة الآلية بأنه معتمد على التمثيل المحايد أو التحويل وتتطلب هذه المناهج معاجم شاملة بمعلومات دلالية وتركيبية وصرفية ومجموعة كبيرة من القواعد.

            ٢- الترجمة المعتمدة على الإحصاء

            تحاول الترجمة الآلية الإحصائية توليد الترجمة باستخدام الطرق الإحصائية المعتمدة على ذخيرة لغوية ثنائية اللغة، فإذا توافرت هذه المكانز، يمكن تحقيق جودة ممتازة في الترجمة الآلية لأى نصوص مشابهة، وأول برنامج للترجمة الإحصائية هو CANDIDE من أي بي ام، وقد استخدمت شركة جوجل SYSTRAN لعدة سنوات ثم انتقلت إلى طريقة الترجمة الإحصائية في أكتوبر ۲۰۰۷ ، وقامت جوجل مؤخرا بإضافة ۲۰۰ مليار كلمة من مواد الأمم المتحدة لتدريب أنظمة الترجمة الآلية، حيث تحسنت جودة الترجمة كثيرا.

            تطبيقات الترجمة الآلية

            -	المساعدة على الفهم مع الانفجار المعلوماتي وتطور النشر العالمي مع استخدام لغات مختلفة أصبح الباحث يلجأ إلى المترجم الآلي للحصول على المعلومات الضرورية لبحثه
            -	 وسيلة رفع الإنتاجية مع ظهور العولمة واتجاه المؤسسة إلى الإنتاج الخارجي أصبح ضروريا عليها مخاطبة الزبائن بلغاتهم ونشر المعلومات عنها (تعريف المنتوج) في المطبوعات مواقع الويب والنشر بلغاتهم المختلفة وهذا العمل يتطلب كفاءة عالية كما أنه عمل روتيني لذا لجأت المؤسسات إلى برامج الترجمة لربح الوقت.
            ويمكن أن تذكر مثال Reverso التي ربحت ما بين 60-30 من وقت العمال في الترجمة باستخدامها برنامج الترجمة من اللغة الإنجليزية إلى مختلف اللغات الأخري تحليل النص المصدر
            -	تطبيق القواعد اللغوية
            وتتكون القواعد اللغوية من: قواعد ترتيب الكلمات المعلومات الإعرابية والنحوية
            المورفولوجيا، تحليل الجمل الدلالة.
            -	 تعميم الترجمة
            -	 القواميس: إن القواميس المدمجة في برمجيات الترجمة الآلية ليست قواميس بها مجموعة كلمات بلغتين أو أكثر بل تحوي كلمات بها معلومات لغوية مورفولوجية دلالية، نحوية في اللغة الأم م واللغة المترجم اليها.

            ５-	 تحليل المشاعر Sentiment Analysis

            تحليل المشاعر Sentiment Analysis هي واحدة من أشهر تقنيات الـ NLP والتي لفتت أنظار العالم في الأونة الأخيرة، فهذه التقنية تحاول فهم المشاعر التي تكمن وراء النصوص وتحديد المواقف الناتجة عنها سواء كانت مشاعر معينة أو حيرة أو سخرية أو شك أو شيء آخر.

            واليوم تستخدم العديد من الشركات هذه التقنية من أجل الرد التلقائي على عملائهم، فهي تستطيع تمييز الشكوى من المدح والتجاوب مع الاثنين بالطرق المناسبة حسب الأوامر المحددة من قبل الشركة.

            ６-	تلخيص النصوص الآلي Automatic Text Summarization

            أتمتة عمليات التلخيص كانت أولوية لدى متخصصين معالجة اللغة الطبيعية على مدى عقود وهذا لكون هذه التقنية تستطيع أن توفر علينا نحن البشر الكثير من الوقت والمجهود اللذان نستغرقهم في أداء هذه المهمة الصعبة.
            والآن يستطيع الباحثون أن يقوموا بتلخيص العشرات من الأبحاث العلمية بمختلف تخصصاتها بدون بذل جهد كبير في معالجتهم والتعامل معهم ما ساعد على توفير وقت كبير لهم في أداء التجارب والأبحاث الخاصة بهم.

            والتلخيص الآلي للنصوص يعد تطبيق من تطبيقات المعالجة الآلية للغة يقوم إنشاء نص مختصر من ملف أو مستند بواسطة برنامج حاسب آلي، على أن يحتوى النص المختصر على أهم الأفكار في النص الأصلي، وتأتى أهمية التلخيص الآلى في ضوء إغراق المعلومات وزيادتها عن قدرة المرء على الملاحقة والمتابعة. ينبغى على البرمجيات التي طورت التقدم خلاصات متماسكة أن تأخذ فى الاعتبار عدة متغيرات مثل الطول وأسلوب الكتابة والبناء من أجل إنشاء ملخص مفيد.

            ويمكن التمييز بين نوعين من برامج التلخيص الآلي برامج الاستخلاص والتجريد. تعتمد برمجيات الاستخلاص على نسخ المعلومات التى تعد مهمة إلى الملخص (مثل الجمل الأساسية والفقرات المهمة أما التجريد أو التركيز فيتطلب إعادة الصياغة، وبصفة عامة، يعد التجريد وإعادة الصياغة أقوى تأثيرا ويركز المعلومات بصورة أكبر من الاستخراج، ولكن البرامج التي تقوم بذلك صعبة للغاية في البرمجة والتطوير لأنها تتطلب تكنولوجيا توليد اللغة الطبيعية التي ما زالت حتى الآن مجالا متناميا.

            ７-	تحليل أراء العملاء Customer Feedback Analysis

            العديد من الشركات تستخدم معالجة اللغة الطبيعية NLP في تحليل أراء عملائها على منصات التواصل الاجتماعي، وخاصة تويتر، فمن خلال الخوارزميات المتخصصة أن تعرف أراء العملاء عن منتجاتك والتحسينات التي يرغبون بها وكل تعليقاتهم. ومن خلال هذا تستطيع عمل مسح موسع لأراء عدد كبير من العملاء بتكلفة أقل وبوقت أقل بكثير، وهذا شيء ضروري للغاية خاصة إذا كانت شركتك تخدم الملايين من العملاء
            ８-	أتمتة مهام خدمة العملاء Automation of Customer Support Tasks
            تواجه أقسام خدمة العملاء في المتوسط المئات من الطلبات والشكاوى يوميا، وعادة ما تكون هذه الأمور مكررة، ولذا تلجأ بعض الشركات إلى أتمتة المهام المتكررة وتقليل عدد العاملين فى أقسام خدمة العملاء، وهذا ما يوفر عليهم أموال كثيرة ويزيد من كفاءة القسم. 
            ９-	تطبيقات المحادثة Chatbots 
            تطبيقات المحادثة Chatbots هي واحدة من أكثر تطبيقات معالجة اللغة الطبيعية شهرة، حيث من خلال الخوارزميات الذكية يمكنك بسهولة توفير ذكاء اصطناعي يرد على عملائك ردود ذكية بشرية، كما يمكنك توفير أنظمة خبراء قادرة على إجابة . أسئلة عملائك. جميع هناك الكثير من التطبيقات الشهيرة حاليا التي تستخدم هذه الخوارزميات، ومن أبرزها أنظمة المساعدة الافتراضية مثل CIRI الخاصة بابل ومساعد جوجل الخاص بجوجل.

            １０-	 تحليل وتصنيف السجلات الطبية Analysis and Categorization of Medical

            Records

            بفضل تطور تقنيات الـ NLP أصبح بإمكاننا تصنيف ومراجعة السجلات الطبية بدون أي تدخل بشري من خلال خوارزميات بسيطة، كما بإمكاننا تحليل هذه السجلات واستخراج المعلومات التي نريدها بشكل أتوماتيكي. هذه التطبيق سيجعلنا قادرين على فهم الأمراض والمرضى بشكل أكثر تطوراً، كما أنه سيجعلنا قادرين على التحكم ومنع انتشار الأمراض المعدية.
            １１-	 التنبؤ بالنصوص Text Prediction

            هذا التطبيق نقوم باستخدامه العديد من المرات يوميا من خلال التنبؤ بالنصوص والتصحيح التلقائي وهما الميزتان الموجودتان على هواتفنا المحمولة، كما أنه يُستخدم بكثرة في محركات البحث

            １２-	 التدقيق اللغوي Proofreading

            العديد من برامج النصوص مثل مايكروسوفت وورد تستخدم تقنيات معالجة اللغة الطبيعية من أجل مراجعة الأخطاء النحوية وتصحيح هذه الأخطاء، وهناك تطبيقات متخصصة فقط في هذا الأمر تقوم بهذا، مثل Grammarly :

            １３-	فلترة رسائل البريد الإلكتروني Email Filters

            هذا التطبيق الذي يساعد على تصنيف البريد الإلكتروني الخاص بـ Gmail جيميل إلى الرسائل الأساسية الرسائل الاجتماعية الرسائل الترويجية بالإضافة إلى تحديد االرسائل المهملة.

            １４-	كشف الانتحال Plagiarism Detection

            مسألة الانتحال Plagiarism مهمة للغاية في الأوساط الأكاديمية، فهي تقارن النصوص التي كتبها الباحثون بتلك المكتوبة من نقل لتحديد نسبة الاقتباس في نصوصهم وأبحاثهم. الصعوبة القيام بهذا يدويًا فإن التطبيقات التي تقوم باستخدام الـ NLP ساعدت المجتمع العلمي كثيرا في هذا الشأن.
            １５-	 التوليد الآلى للغة

            يقصد بالتوليد الآلى اللغة إنشاء نص بلغة طبيعية من نظام تمثيل الى مثل قاعدة معرفة أو استمارة منطقية، وبعض الناس يعتبر التوليد الآلى للغة كمقابل لفهم اللغة الطبيعية، وفي نظم إنشاء التوليد الآلى للغة، يحتاج النظام إلى اتخاذ قرارات بشأن كيفية صياغة أحد المفاهيم. وأنجح التطبيقات للتوليد الآلى للغة أنظمة تحويل البيانات إلى نصوص التي تقوم بإعداد خلاصات نصية للبيانات الرقمية وغير اللغوية حيث تمزج بين تحليل البيانات والتوليد الآلى للغة مثل النشرات الآلية لأحوال المناخ والاقتصاد والبورصة.

            １６-	 التنقيب في النصوص

            يقصد به عملية استخلاص معلومات عالية الجودة من النصوص وتستمد المعلومات عالية الجودة من تقسيم الأنماط والاتجاهات من خلال وسائل مثل التعلم الإحصائي للأنماط وتتضمن عملية التنقيب في النصوص هيكلة النصوص المدخلة من خلال الإعراب الفك إلى الوحدات اللغوية مع إضافة مزايا لغوية مشتقة وإزالة مزايا أخرى والإدخال التالي في قاعدة البيانات واشتقاق الأنماط داخل البيانات المهيكلة وفى النهاية تقييم وتفسير المخرجات تتضمن مهام التنقيب في النصوص تصنيف النصوص وعنقدتها واستخراج المفاهيم والهويات وإنتاج التصنيفات المتدرجة وغيرها. وتستخدم تقنيات التنقيب في النصوص في تطبيقات الحماية والرعاية الطبية والبرمجيات والتطبيقات وتحسين نتائج البحث وأغراض التسويق والتطبيقات الأكاديمية.

            １７-	 التعرف الضوئى على الحروف Optical Character Reading

            يقصد بالتعرف الضوئي على الحروف OCR التحويل الميكانيكي أو الإلكتروني لصور الكتابة اليدوية أو الكتابة بالآلة الكاتبة أو النص المطبوع، والتى يتم عادة التقاطها بالماسحة الضوئية إلى نص قابل للتحرير والقراءة فى الحاسب. وقد بلغت تقنية التعرف الضوئي على الحروف شأوا كبيرا في اللغات اللاتينية بل لم تعد مشكلة على الإطلاق، وفى اللغة العربية توجد تطبيقات متطورة للتعرف الضوئي على الحروف العربية المطبوعة من صخر غير أنها باهظة التكلفة وقليلة الانتشار. وما زال التعرف الضوئى على الكتابة باليد أو الكتابة المنحنية المتصلة مجالا للبحث النشط سواء فى اللغات اللاتينية أو اللغة العربية.

            １８-	 نمذجة الموضوعات

            أمر مشابه لتصنيف الموضوعات، يجد هذا المثال الخاص بمعالجة اللغة الطبيعية الموضوعات ذات الصلة في النص عن طريق تجميع النصوص ذات الكلمات والتعبيرات المتشابهة، وعندما لا تكون بحاجة إلى إنشاء قائمة بالتصنيفات المحددة مسبقاً أو وضع بيانات تحت أي تصنيفات فهو خيار جيد للتحليل الاستكشافي، أي عندما لا تكون على دراية ببياناتك بعد.

            １９-	تحويل النص إلى كلام منطوق

            من التطبيقات المهمة للمعالجة الآلية للغة، فهو يقوم بقراءة النصوص أو تحويل الكلام المكتوب إلى صوت مسموع وكلام منطوق مفهوم، ويسمى نظام الحاسب برمجيات أو أجهزة) المستخدم لهذا الغرض بمولف الكلام، ويقوم نظام تحويل النص إلى كلام بتحويل نص اللغة العادية إلى كلام، أما الأنظمة الأخرى فتعمل على تحويل الرموز اللغوية الصوتية إلى كلام يمكن إنشاء الكلام المؤلف من خلال ضم أجزاء متسلسلة من الحديث المسجل المخزن في قاعدة بيانات هي المكائز المنطوقة، وتختلف الأنظة فى حجم وحدات الحديث المخزنة، وفي مجالات استخدام معينة، يتيح تخزين كلمات كاملة أو جمل كاملة إنتاج كلام عالى الجودة. وهناك طريقة أخرى هى تضمين نموذج من جهاز النطق وغيرها من خصائص الصوت الإنساني لإنتاج صوت مولف بالكامل.

            ويتم الحكم على جودة مولف الكلام بدرجة تماثله مع الصوت البشرى أو بمدى فهمه، ويتيح برنامج تحويل النصوص إلى كلام مفهوم للمكفوفين والمعاقين بصريا الاستماع إلى الأعمال المكتوبة من خلال الحاسب المنزلي، وقد تضمنت العديد من أنظمة تشغيل الحاسب مولفات كلام منذ بداية الثمانينات. المشكلة التي تواجه إنتاج مولفات كلام باللغة العربية هي غياب علامات التشكيل، ولهذا لابد من إنتاج المشكل الآلى حتى يمكن تحويل النصوص العربية إلى كلام منطوق.

        `,
    },
    {
        "id":2,
        "type": "lesson",
        "title": "الدرس الثالث",
        "video": "https://res.cloudinary.com/dtxava86t/video/upload/v1683579911/video/lesson3.mp4",
        "sub-title": "تطبيقات معالجة النصوص:",
        "desc": `
            ان لخوارزميات معالجة النصوص تطبيقات مختلفة بعضها قد لا يبدو متوقعا كاستخدام مباشرة لها ونذكر هنا بعضها لتوضيح حجم وأثر معالجة النصوص على واقع العلم الحديث:

            １.	التطبيقات الطبية الحيوية : (Biomedical) حيث تم الاستفادة من خوارزميات معالجة النصوص في هذه المجالات لاستخلاص أنماط الأعراض من بيانات المرضى، وكذلك من سلاسل الأحماض النووية، ومن بين هذه الخوارزميات خوارزميات نمذجة المواضيع Topic Modeling .
            ２.	تطبيقات تسويقية حيث يستفاد من تقنيات معالجة النصوص في التعرف على طبيعة علاقة الشركات بعملائهم وآرائهم وانطباعاتهم حول منتجات وخدمات الشركات. 
            ３.	علم الاجتماع الحسابي : (computational sociology) حيث يتم الاستعانة بتقنيات تجميع النصوص والترجمة الآلية والتعلم العميق لتحليل النصوص الهائلة المتوافرة على الإنترنت ومن عدة لغات من قبل علماء الاجتماع للبحث والاستكشاف.

            المجالات التي تستخدم معالجة اللغة الطبيعية :-

            تعمل معالجة اللغة الطبيعية على تبسيط وأتمتة مجموعة واسعة من عمليات الأعمال، وخاصة تلك التي تتضمن كميات كبيرة من النصوص غير المهيكلة مثل رسائل البريد الإلكتروني والاستطلاعات ومحادثات الوسائط الاجتماعية وغير ذلك الكثير مع معالجة اللغة الطبيعية، يمكن للشركات تحليل بياناتها بشكل أفضل للمساعدة في اتخاذ القرارات الصحيحة فيما يلي بعض الأمثلة على التطبيقات العملية لـ: NLP

            . الرعاية الصحية : مع انتقال أنظمة الرعاية الصحية في جميع أنحاء العالم إلى السجلات الطبية الإلكترونية، فإنها تواجه كميات كبيرة من البيانات غير المنظمة. يمكن استخدام معالجة اللغة الطبيعية لتحليل والحصول على رؤى جديدة في السجلات الصحية.
            . قانوني : للتحضير لقضية ما، يجب على المحامين في كثير من الأحيان قضاء ساعات في فحص مجموعات كبيرة من المستندات والبحث عن مواد ذات صلة بقضية معينة. يمكن لتقنية NLP أتمتة عملية الاكتشاف القانوني، والتخلص من كل من الوقت والخطأ البشري من خلال التحريك عبر كميات كبيرة من الوثائق.

            . الإدارة المالية : يتحرك العالم المالي بسرعة كبيرة، وأية ميزة تنافسية مهمة في المجال المالي ، يستخدم التجار تقنية NLP لتعدين المعلومات تلقائيًا من مستندات الشركات والإصدارات الإخبارية لاستخراج المعلومات ذات الصلة بحافظاتهم وقراراتهم التجارية.

            . خدمة العملاء : تستخدم العديد من الشركات الكبيرة المساعدين الافتراضيين أو روبوتات المحادثة للمساعدة في الإجابة على استفسارات العملاء الأساسية وطلبات المعلومات (مثل الأسئلة الشائعة)، مع طرح الأسئلة المعقدة على البشر عند الضرورة. . . التأمين : تستخدم شركات التأمين الكبيرة معالجة اللغة الطبيعية للتنقل المستندات عبر والتقارير المتعلقة بالمطالبات، في محاولة لتبسيط طريقة إنجاز الأعمال.

            الاتجاهات الرئيسية لمعالجة اللغات الطبيعية :-

            . المنهج القاعدي أو اللغوي
            . المنهج الأحصائي أو المبني علي المتن أو المكنز أو المدونة اللغوية
            .المنهج المختلط القائم على المنهجين اللغوي والإحصائي

            １-	 المنهج القاعدي

            الأساليب اللغوية المعتمدة على القواعد والمتعلقة بمهام التعرف على كيانات الأسماء مثل الأساليب المستخدمة في نظام استخراج المعلومات ANNIE الخاص بمنصة GATE تتكون عادة من مزيج من معاجم كيانات الأسماء وقواعد مطابقة الأنماط المشفرة يدويا. تستخدم هذه القواعد معلومات مأخوذة من السياق للمساعدة في تحديد ما إذا كانت الكيانات المحتملة الموجودة في معاجم كيانات الأسماء صحيحة، أو لزيادة عدد الكيانات المحتملة تعد معاجم كيانات الأسماء بمنزلة نقطة الانطلاق التي تتيح تأكيد أو رفض أو تنقيح الكيان النهائي الذي ينبغي استخراجه تتكون منظومة التعرف على كيانات الأسماء وتصنيفها عادة من عملية معالجة لغوية مسبقة تجزئة الجمل، تقسيم الجمل، تصنيف أقسام الكلام كما سبق شرحه في الفصل السابق تليها عملية إيجاد الكيان بواسطة معاجم كيانات الأسماء والقواعد النحوية، ثم عملية استخراج الإحالات المشتركة.

            صممت معاجم كيانات الأسماء لإضافة التعليقات والشروحات البسيطة والاعتيادية مثل الأسماء المعروفة للشركات والمواقع وأيام الأسبوع والمشاهير وما إلى ذلك. قد تحتوي معاجم كيانات الأسماء النموذجية الخاصة بالتعرف على كيانات الأسماء وتصنيفها على مئات أو آلاف المدخلات غير أن استخدام معاجم كيانات الأسماء ليس كافيًا بحد ذاته للتعرف على الكيانات وتصنيفها، وذلك لأن الكثير من الأسماء يتسم بالغموض على سبيل المثال: «لندن» قد تكون جزءا من اسم منظمة أو شخص، أو قد تكون المدينة المعروفة ببساطة هذا من ناحية ومن ناحية أخرى، لا يمكنها تحديد كل كيان من كيانات الأسماء (على سبيل المثال في اللغة الإنجليزية لا يمكن للمرء أن يحدد مسبقا جنس كل لقب عائلي. لكن عند دمج معاجم كيانات الأسماء مع حواشي المعالجة اللغوية الأخرى بطاقات تصنيف أقسام الكلام، الأحرف الكبيرة، وغيرها من الأدلة السياقية الأخرى، فإنها قد تكون قوية جدا.

            يجري تطوير الأنظمة القواعدية بناءً على الخصائص اللغوية، مثل بطاقات تصنيف أقسام الكلام أو المعلومات المستنقاة من السياق وبدلاً من وضع هذه القواعد بصورة يدوية، من الممكن وضع علامات على الأمثلة التدريبية، ومن ثم تعلم القواعد بصورة آلية باستخدام أنظمة تعلم القواعد (تعرف أيضا بأنظمة استقراء أو استنتاج الأدلة عن طريق التعلم الخاضع للإشراف، تقوم هذه الأنظمة باستنتاج مجموعات القواعد الأمثلة التدريبية التي وضعت عليها العلامات. كانت هذه الأنظمة تحظى بشعبية في أنظمة التعلم المبكرة التي كانت تستخدم في مهام التعرف على كيانات الأسماء وتصنيفها، وكان من بينها أنظمة من قبيل SRVو
            LP  . و BWI  و  WHISK و  RAPIER
            ２-	المنهج الأحصائي أو المبني علي المتن أو المكنز أو المدونة اللغوية

            لم يكن ممكنا للمعالجة الآلية للغات أن تتقدم وتفتح لنفسها مجالات التطبيق المتنوعة السابقة ثم تستشرف المستقبل بدون أن يكون لها قلب نابض يستوعب مليارات الكلمات والأصوات وتكون لديه القدرة على الوصول إلى أى منها وفهم وتحليل ما بينها من علاقات، ليصبح مع الوقت بيتا للذاكرة ونبع متدفق للمعرفة، وعمليا تجسد هذا القلب النابض فيما يعرف بالمكائز اللغوية Corpora التى تعتمد في عملها على قوة الحاسبات فى المعالجة وقدرات البرمجيات المختلفة في التحليل والفهرسة والرصد والاسترجاع، وسعات وحدات التخزين في استيعاب ما لا حصر له من الكلمات والأصوات فما هي المكانز اللغوية؟

            وفقا لموقع جامعة إيسيكس www.essex.ac.uk ، فإن هذا المصطلح يشير إلى المجموعات الكبيرة من النصوص أو الملفات الصوتية التى تمثل عينة أو تخصص أو شريحة معينة من اللغة، وهذه النصوص تكون غالبا في صيغة الكترونية يستطيع الحاسب قراءتها والبحث فيها، ومن الممكن أن يتكون المكنز اللغوى من نصوص خام فقط بدون أى معلومات أو يحتوى على معلومات لغوية خاصة تسمى بالحواشي أو التلقيب أو الوصف.

            وهي إما مكانز نصية تحتوى على مجموعة هائلة من النصوص المكتوبة والمطبوعة مثل النصوص الكاملة للصحف والمجلات والكتب فى مختلف المجالات مثل الآداب والسياسة والعلوم والفنون أو مكائز صوتية منطوقة تحتوى على تسجيلات آلاف المحادثات والحوارات والخطب ونشرات الأخبار الإذاعية والبرامج الحوارية والمسلسلات والأفلام وغيرها.

            مجالات استخدام المكانز :

            للمكانز دور محوري فى بناء القواميس والمعاجم الحديثة وفى التعرف على خصائص اللغة وكذلك حل مشكلاتها المختلفة، ذكر الباحثون عدة جوانب لأهمية المكائز في الدراسات اللغوية تذكر أهمها فيما يلى: 
            اولا : صناعة المعاجم 

            تساعد المكانز اللغوية على معرفة معلومات غاية فى الأهمية لبناء المعجم وهي متابعة الكلمات الجديدة التى تدخل اللغة وتحديد وقت دخولها، ومعرفة الكلمات الموجودة بالفعل التي اكتسبت معنى جديدا، ونجد أن أغلب قواميس ومعاجم اللغة الإنجليزية تحتوى على تواريخ مفصلة لكل كلمة وأصلها اللغوى ومتى تم نحتها أو استخدامها لأول مرة، وبمساعدة المكانز الالكترونية يستطيع خبراء صناعة المعاجم البحث في ملايين الجمل والسياقات المختلفة واستدعاء جميع الأمثلة لكلمة معينة لمعرفة استخداماتها والألفاظ التي ترد عادة قبلها أو بعدها من أجل تحديد التعابير الاصطلاحية والمتتاليات اللغوية، الأمر الذى يسهل تعلم اللغة على الأجانب.

            ثانيا: المكانز اللغوية وفهم قواعد النحو

            يمكن الاستفادة من المكائز فى دراسة الملامح الصرفية والبحث عن السوابق واللواحق المعينة التي تدخل على الكلمة فكلمة (علم) تتعدد معانيها بإضافة سوابق أو لواحق مختلفة لتصبح (علمية، علمتنا، علماء، تعليم، علوم، بجانب تحديد توزيع الكلمة وموقعها في الجملة، وهل تأتي قبل الاسم أم بعد الاسم، وقبل الصفة أم بعد الصفة.

            ثالثا: المكائز اللغوية وتحديد الدلالة

            في السنوات الأخيرة، ظهر اتجاه جديد يعتمد على استخلاص معنى الكلمة من المكائز اللغوية، وتتنوع المعلومات الدلالية بين الترادف والتضاد إلى علاقات أكثر تعقيدا، ويمكن استخلاص هذه المعلومات بسهولة من المكانز اللغوية، وينبغى التنبيه انه يشترط لاستخراج هذه المعلومات أن تكون المكائز شاملة وكاملة بقدر المستطاع حتى لا يتسرب معنى أو استخدام لا توجد أمثلة له في المكنز. 
            رابعا: المكانز اللغوية وتحسين تعليم اللغات الأجنبية

            من خلال المكانز من الممكن تحليل مدى تكرار وشيوع الكلمات ومعرفة تأثير السياق أو الموقف على أسلوب اللغة وهى معلومات مفيدة للغاية في وضع مناهج تعليم اللغة العربية سواء للطلاب الأجانب أو العرب أنفسهم أيضا باستخدام المكانز اللغوية، يستطيع واضع المراجع والمواد إنشاء تمرينات تعتمد على أمثلة حقيقية تقدم للطلاب فرصة اكتشاف خصائص استخدام اللغة. وبدلا من الاعتماد على البحث فى معاجم تقليدية قديمة، يستطيع الطلاب البحث بأنفسهم في برامج المكانز اللغوية من خلال برنامج بحث وإحصاء لغوى متخصص ( concordance) ويكتشفوا بأنفسهم استخدامات اللغة وقواعدها وخصائصها، ويشجع ذلك على استقلال الطلاب في التوصل إلى نتائج جديدة بدلا من تعليمهم نتائج متوقعة أو معروفة مسبقا.

            خامسا: المكانز اللغوية في مجالات أخرى

            وفي علم اللغويات الاجتماعية، ينصب التركيز على تأثير العمر والنوع والطبقة الاجتماعية والمهنة في استخدام الأفراد للغة، ولا يمكن دراسة ذلك بشكل سريع ودقيق إلا في المكائز اللغوية التي تفيد أيضا فى دراسة الأسلوب وتأثره بالمقام أو مقتضى الحال، فالكتابات الأدبية تختلف عن الكتابات السياسية، والكتابات التعليمية تختلف عن المحادثات العادية، وهكذا، وفي كل الأحوال، ينبغي أن تتسم المكانز اللغوية بالشمول، حتى تكون النتائج التي يتم استخلاصها من الدراسة دقيقة وواقعية.

            المكانز واللغة العربية

            تم تلخيص أهمية المكانز اللغوية لبناء معاجم اللغة العربية في الجوانب التالية:

            １-	حصر جميع المعاني من مميزات البحث الإلكترونى فى المكائز اللغوية إمكانية عرض جميع السياقات التي يمكن أن تظهر فيها الكلمة، وبالتالى إمكانية حصر كل المعاني المختلفة لنفس الكلمة حسب السياقات المختلفة، ومن أمثلة ذلك كلمة (قلب) التى تعنى جوهر وقلب يضخ الدماء ووسط أو منتصف.

            ２-	دراسة مدى شيوع الكلمات تساهم المكانز اللغوية في معرفة أكثر الكلمات شيوعا في اللغة العربية على المستويين المنطوق والمكتوب، وذلك من أجل تعليم هذه الكلمات للأجانب وحتى يتمكنوا من فهم المعاجم العربية، ومما لا شك فيه أن معرفة مستوى شيوع كلمة ما يدل على أهميتها في كل اللغة المكتوبة أو المنطوقة، وبالتالي ترشد المتعلم إلى معرفة مدى ضرورة تعلمها أو إغفالها من عدمه.

            ３-	 دراسة التنويعات المعجمية دراسة تكرار الكلمة كمادة أو كفئة معجمية (اسم، فعل، صفة غير ذلك، ومن الممكن أن يكون للكلمة الواحدة أكثر من فئة معجمية حسب السياق، مثال ذلك كلمة (عين) التي ترد كاسم وكفعل مع التشديد بمعنى (وظف)

            ４-	دراسة استخدام المترادفات تحتوى اللغة على كلمات عديدة تعتبر مترادفات لبعضها البعض، ومن خلال المكنز اللغوى يستطيع الباحث بسهولة معرفة مترادفات الكلمة ومعدل شيوعها.

            ５-	 شكل الكلمة وفقا لحالتها الإعرابية يتغير شكل الكلمة وفقا لحالتها الإعرابية (الرفع والنصب والجر)، ويمكن للباحث من خلال المكنز اللغوى معرفة التنويعات في شكل الكلمة. 

            ６-	دراسة الكلمة وفقا لاشتقاقها الصرفي: فهناك كلمات ذات أكثر من اشتقاق صرفي مثل كتب التي يمكن اشتقاق كاتب وكتاب ومكتبة ومكتوب وغيرها فالمكنز اللغوى يفيد كثيرا في هذه الحالات.

            ７-	معرفة مدى السلامة والصحة اللغوية: أحيانا يكون للكلمة أكثر من جمع أو هي نفسها أكثر من شكل، ويمكن اللجوء إلى ذخيرة المكنز اللغوية الهائلة والبحث فيها لمعرفة أكثر هذه الأشكال شيوعا واستخداما في اللغة، مثل (شهور وأشهر) و (عيون وأعين)، وهكذا.
            ８-	معرفة المتصاحبات اللغوية والتعبيرات الاصطلاحية: هناك أوصاف أو كلمات دائما تقترن بأوصاف أو كلمات أخرى دون سبب ظاهر أو منطقي، مثل تعبيرات فتح الباب على مصراعيه) و (رأب الصدع) و(العروة الوثقى) ودراسة المكائز اللغوية تفيد للغاية في البحث عن أمثلة هذه المتصاحبات من أجل تسجيلها في موادها بالمعجم العربي الحديث. فمثلا في مادة عروة ينبغي أن يذكر القاموس أنه دائما تليها كلمة (وثقى)، وهكذا.

            كيف تم وضع قواعد اللغة العربية منذ أكثر من ألف عام؟ وهل القواعد تسبق الاستخدام أم العكس؟

            من المعروف أن الاستخدام يأتى أولا ثم تأتى القاعدة بعد ذلك، الأمر الذي مكن النحاة الأوائل من وضع القواعد بناء على الاستخدام أو الاستعمال اللغوي، فقاعدة رفع الفاعل ونصب المفعول وجر المضاف إليه جاءت من دراسة استخدام هؤلاء الأفذاذ للاستعمالات اللغوية في أبيات الشعر والحديث والقرآن، وبالمثل يمكن الاستفادة من المكائز اللغوية في استخلاص القواعد اللغوية على مستوى الكلمة والجملة والخطاب والحصول على معلومات عن تركيب واستخدام العديد من التعبيرات اللغوية.

            طرق عمل المكانز :

            １-	جمع المادة النصية عن طريق جمع المادة الالكترونية المتوفرة على الأقراص الضوئية أو الشبكات أو من خلال الإدخال اليدوى عن طريق لوحة المفاتيح و عن طريق تحويل المادة المنطوقة إلى مادة مكتوبة إن وجدت عن طريق المحولات الصوتية وتحويل البيانات الصورة يسهل التعامل معها آليا مثل صيغة النصوص text أو عن طريق جهاز المسح الضوئي الذي يحول النصوص فى المستندات الورقية إلى الصيغة الإلكترونية.

            ２-	 تجهيز المادة اللغوية وهى مرحلة ما قبل المعالجة: يقصد بذلك عزل الجمل وتقسيم الجمل وعزل الصور وتوحيد الخطوط وحجم الخط وخلافه وعزل علاقات الترقيم وتمييز اللبس والاختصارات والقوائم والشروط بأنواعها .
            ３-	إدخال معلومات الوصف والترميز والتلقيب المناسبة : يقصد التلقيب annotation أو الوصف metadata أو الترميز markup تحديد المعلومات اللغوية وبيانات المؤلف وتاريخ الإنشاء والعنوان واللغة والمجال وادخال المعلومات اللغوية مثل فئات أو أقسام الكلام والمشتقات والمعلومات النحوية وبناء الجملة والمعلومات الدلالية ومعلومات عن الأسلوب والصوت بصيغة يفهمها برنامج البحث في المكنز، وسائر أدوات معالجة اللغة، وتتضمن معلومات الوصف تمييز حدود الجمل والعبارات والفقرات وفك لبس حدود الجمل من خلال النقطة والمسافة وتمييز الكلمة الجذر Lemma ومشتقاتها.

            مستويات تحليل اللغات الطبيعية :-

            بالنسبة للنصوص المكتوبة ، فإن تحليها يمر في عدة مراحل تختلف باختلاف طريقة التحليل ، ولكن إحدى معظم أكثر أساليب التحليل إنتشارا تتبع المراحل :

            １-	التحليل الصرفي

            وهو الذي يهتم بمعرفة نوع الكلمات، وضمائرها وغيرها من المعلومات الصرفية كتحديد هل هي جمع أم مفرد صيغة تذكير أم تأنيث صيغة ماضي أم مضارع بالإضافة إلى تحديد أصل الكلمة والزوائد الدخيلة عليها.

            ２-	 التحليل النحوي

            وهو المعتمد على التحليل الصرفي، ويهتم بهيكلة الجملة وعلاقة كلمات بعضها مع بعض وغيرها من المعلومات النحوية كتحديد الفعل والفاعل والمفعول به لتحليل البنية النحوية للجملة إن كانت اسمية أو فعلية أو مشروطة محددا أداة الشرط وجواب الشرط.

            ３-	التحليل الدلالي

            المعتمد على المرحلتين السابقتين، ويهتم بقصد الجملة عن طريق الربط وهو المنطقي بالمعلومات الموجودة في الجملة وبين العالم الواقعي .

            المنهجيات المتبعة في المعالجة اللغوية في اللغة العربية :-

            هناك نوعان رئيسان من المنهجيات المتبعة في مهام المعالجة اللغوية: أحدهما منهجية قائمة على المعرفة والآخر منهجية مبنية على التعلم، علما أنه يمكن أيضا دمجهما معا، هناك مزايا وعيوب لكل منهجية، ملخصة في الجدول التالي

            المنهجية القائمة على المعرفة أو القائمة على القواعد تعد من الأساليب التقليدية بصفة عامة وقد حلت محلها في كثير من الحالات منهجيات التعلم الألي نظرا لأن عملية معالجة كميات هائلة من البيانات بسرعة وكفاءة لم تعد تشكل معضلة بقدر ما كان الأمر عليه في الماضي، تستند المنهجية القائمة على المعرفة على قواعد مكتوبة بدوياً، وتجري كتابة هذه القواعد عادة على يد متخصصين في مجال معالجة اللغات الطبيعية وتتطلب معرفة قواعد اللغة والمهارات اللغوية، فضلا عن امتلاك ملكة البديهة. تكون هذه المنهجيات ذات فائدة أكبر إن أمكن تعريف المهمة بسهولة بواسطة القواعد ( على سبيل المثال قاعدة الاسم الصحيح – في اللغة الإنجليزية يبدأ دائما بحرف (بير»)، وفي العادة، يمكن استثناء هذه القواعد بسهولة. عندما لا تنطبق القاعدة اللغوية بشكل مباشر تولد هذه المنهجية إشكالية أكبر من السابق ( على سبيل المثال: في تغريدات تويتر غالبا لا يستخدم الناس الأحرف الكبيرة لكتابة الأسماء الصحيحة في اللغة الإنجليزية). من بين المزايا الكبيرة للمنهجية القائمة على المعرفة السهولة الكبيرة في فهم النتائج. عندما يتعرف النظام على شيء ما بشكل غير صحيح، يكون بوسع المطور التحقق من القواعد وتحديد سبب حدوث الخطأ، ومن ثم يحتمل أن يكون بمقدوره تصحيح القواعد أو كتابة قواعد إضافية لحل المشكلة. ومع ذلك، يمكن أن تستهلك عملية كتابة القواعد الكثير من الوقت، وفي حال حدوث تغيير في المهمة، فقد يضطر المطوّر إلى إعادة كتابة العديد من القواعد

            منهجيات تعلم الآلة تحظى بشعبية أكبر في الأونة الأخيرة مع ظهور أجهزة قوية ومتطورة وأيضا بسبب عدم وجود ضرورة لامتلاك خبرة في المجال المعني أو امتلاك معرفة لغوية، ولذلك أصبح بالإمكان أن تنشئ نظامًا خاضعا للإشراف بسرعة كبيرة إذا توفرت بيانات تدريبية كافية، وبوسعنا الحصول على نتائج معقولة بعد تدريب محدود جدا. غير أن الحصول على بيانات تدريبية كافية أو إنشاءها غالبا ما يطرح إشكالية كبيرة للغاية ويستغرق وقتا طويلا  

            ولا سيما إذا كان لا بد من القيام بهذه العملية يدويا. يعني هذا الاعتماد على بيانات التدريب أيضا أن التكيف مع أنواع جديدة من النصوص أو المجالات أو اللغات سيكون مكلفا على الأرجح، حيث يتطلب توفر قدر كبير من بيانات التدريب الجديدة. لذا، فإن القواعد التي يكون البشر قادرين على قراءتها عادة ما تكون أسهل في التكيف مع اللغات وأنواع النصوص الجديدة مقارنة بتلك المبنية على أساس النماذج الإحصائية. كما يمكن معالجة مشكلة توفر بيانات التدريب الكافية عبر الدمج بين التعلم الآلي والطرق غير الخاضعة أو شبه الخاضعة للإشراف مع العلم أنها عادة ما تعطي نتائج أقل دقة مقارنة بنتائج التعلم الخاضع للإشراف

            تصنيف أقسام الكلام Part of speech tagging :-

            تحتاج الآلات عند التعامل مع اللغة أو النصوص إلى تحديد أو تصنيف أقسام الكلام، وهو ما يتم من خلال تقنية تصنيف اقسام الكلام Part of speech tagging ، إذ يتم تقسيم الجملة إلى أجزائها من أفعال وصفات وأسماء وأحوال وغيرها، وهذا ما يساعد الآلة على الفهم الصحيح للنص أو الصوت الذي يرسله لها الإنسان.
            فك التباس معاني الكلمات Word Sense Disambiguation أو WSD :-

            بعض الكلمات لديها العديد من المعاني بل ولديها العديد من الأشكال النحوية (اسم، فعل، ....) وهو ما قد يسبب التباس للآلة، ويتطلب استخدام خوارزميات محددة من أجل معالجة هذه المشكلة

            تقنية فك التباس معاني الكلمات Word Sense Disambiguation أو WSD تتعامل مع سياق الجملة، ومن خلاله تستطيع أن تحدد المعنى المراد والمقصود لهذه الكلمة، ويتم هذا من خلال نماذج إحصائية معقدة مع ترجيح الكلمات ذات نسب الترجيح الأكبر.

            ويمكن القول بأن هذه التقنية هي ما تمكن الآلة من الحصول على حس لمعنى الكلمات والتفرقة بينها أي أنها من أهم التقنيات التي تجعل الآلة تفهم اللغة الطبيعية.

        `,
    },
    {
        "id":3,
        "type": "lesson",
        "title": "الدرس الرابع",
        "video": "https://res.cloudinary.com/dtxava86t/video/upload/v1683583188/video/lesson4.mp4",
        "sub-title": "مراحل معالجة النصوص NLP",
        "desc": `
            المرحلة الأولى: تجزئة الجمل Sentence Segmentation
            إن المرحلة الأولى في مراحل معالجة اللغات الطبيعية هي تقطيع النص إلى الجمل المكون منها، فمن النص السابق المدروس تكون الجمل: كل جملة من جمل النص تعبر عن فكرة معينة كما هو الأمر بالنسبة لأي نص في اللغة الطبيعية، لذلك يكون من الأسهل أن نجعل الحاسوب يفهم فكرة جملة إلى أن يصل إلى فهم كامل النص المؤلف من هذه الجمل. ومن الشائع في تقطيع النصوص الاعتماد على علامات التنقيط حيث تشكل علامات التنقيط الفاصل بين جمل النص، وفي حال لم يكن النص منسقا باستخدام علامات التنقيط فيمكن اعتماد طرق أكثر تعقيدا لتقطيع النص والحصول على جمله.

            المرحلة الثانية: الحصول على الوحدات اللغوية Tokenization
            في المرحلة الثانية سنقوم بتقطيع الجمل التي حصلنا عليها إلى الوحدات اللغوية Tokens ، في حالتنا تتمثل token بالكلمة word ، ويمكن أن تتم هذه المرحلة من المعالجة على التسلسل أي معالجة جملة تلو الجملة الأخرى.
            لنأخذ الجملة الأولى من النص المدروس على سبيل المثال مدينة دمشق هي عاصمة الجمهورية العربية السورية و أكبر المدن السورية من حيث الكثافة السكانية" تتمثل هذه المرحلة التي تدعى Tokenization الحصول على الوحدات اللغوية) بتقطيع الجمل إلى كلماتها، فإذا طبقنا عملية الحصول على الوحدات اللغوية على الجملة المدروسة ستحصل على الكلمات التالية:
            مدينة "دمشق"، "هي"، "عاصمة الجمهورية"، " العربية"، "السورية"، "و" أكبر"، "المدن"، "السورية"، "من"، "حيث"، "الكثافة"، "السكانية"، "". إن عملية الحصول على الكلمات في اللغة الإنجليزية بسيط لأنه يمكن أن يكون الفراغ هو الفاصل بين كلمات الجمل أما بالنسبة إلى اللغة العربية فالأمر أكثر تعقيدا، لوجود ضمائر متصلة بالكلمة وكل ضمير يحمل معنى مختلفاً تفصل علامات التنقيط كوحدة لغوية Token مستقلة، وذلك لأننا نعرف أن كل علامة تنقيط لها معنى مختلف عن الأخرى.

            المرحلة الثالثة: التنبؤ بأقسام الكلام  
            ستقوم في هذه المرحلة بإسناد كل وحدة لغوية إلى قسم الكلام المناسب لها سواء كان أسماء أو "مدينة"، "دمشق"، "هي"، "عاصمة الجمهورية"، " العربية"، "السورية"، "و"، أكبر"، "المدن"، "السورية"، "من"، "حيث"، الكثافة"، "السكانية"، ".".  إن عملية الحصول على الكلمات في اللغة الإنجليزية بسيط لأنه يمكن أن يكون الفراغ هو الفاصل بين كلمات الجمل أما بالنسبة إلى اللغة العربية فالأمر أكثر تعقيداً، لوجود ضمائر متصلة بالكلمة وكل ضمير يحمل معنى مختلفا. سنقوم في هذه المرحلة بإسناد كل وحدة لغوية إلى قسم الكلام المناسب لها سواء كان أسماء أو فعلا أو صفة.  تفصل علامات التنقيط كوحدة لغوية Token ،مستقلة، وذلك لأننا نعرف أن كل علامة تنقيط لها معنى مختلف عن الأخرى.   موسومة tagged  لنأخذ باعتبارنا أن النموذج يعتمد بشكل كلي على الإحصاءات ومهما كانت نتائجهم صحيحة لكنه بالتأكيد لن يفهم ماذا تعني الكلمات في الحقيقة كما نفهمها نحن كبشر. إن النموذج يعرف فقط كيف يتنبأ بأقسام الكلام بناء على الجمل والكلمات التي مررت له سابقاً. بعد معالجة الجملة التالية تعتبر مدينة دمشق من أقدم العواصم المأهولة في العالم" يمكن أن نحصل على النتيجة التالية:  دمشق  "فعل"  اسم علم"  حرف جر  اسم  العواصم  المأهولة  العالم  "اسم"  اسم "  حرف  اسم"  عند حصولنا على هذه المعلومات، ستستطيع البدء بجمع المعاني الأساسية، على سبيل المثال بعد معرفتنا أن الأسماء تضم "دمشق" و "العواصم" فإن الجملة ربما تتحدث عن دمشق. 
            المرحلة الرابعة أصل كلمات  النص  Lematization  تظهر الكلمة في اللغات الطبيعية بأشكال مختلفة ، مثلا في اللغة الإنجليزية يضاف حرف 8 إلى آخر بعض الكلمات لتعبر عن الجمع، أما في اللغة العربية فتضاف بعض الحروف وتحذف بعضها لتعبر عن حالات مختلفة في علم الصرف للغة العربية، وأصل الكلمة هو الشكل الأساسي لها على سبيل المثال فإن الشكل الأساسي لكلمة يحتاجون" في اللغة العربية هي احتاج" وكذلك الشكل الأساسي لكلمة "studied" في اللغة الإنكليزية "study".  ومن المفيد أن يعرف الحاسوب أصل الكلمات أي شكلها الأساسي كي يعرف أن الجمل التي تحتوي هذه الكلمات تدل على مفهوم واحد. فكما تعلم عزيزي القارئ أن الحاسوب يفهم الكلمات كلها كمعارف فإذا اختلفت هذه المحارف ولو اختلافا بسيطا اعتبرها الحاسوب كلمة مختلفة  Lematization  تظهر الكلمة في اللغات الطبيعية بأشكال مختلفة ، مثلا في اللغة الإنجليزية يضاف حرف و إلى آخر بعض الكلمات لتعبر عن الجمع، أما في اللغة العربية فتضاف بعض الحروف وتحذف بعضها لتعبر عن حالات مختلفة في علم الصرف للغة العربية، وأصل الكلمة هو الشكل الأساسي لها على سبيل المثال فإن الشكل الأساسي لكلمة يحتاجون" في اللغة العربية هي احتاج" وكذلك الشكل الأساسي لكلمة studied في اللغة الإنكليزية "study.  ومن المفيد أن يعرف الحاسوب أصل الكلمات أي شكلها الأساسي كي يعرف أن الجمل التي تحتوي هذه الكلمات تدل على مفهوم واحد فكما تعلم عزيزي القارئ أن الحاسوب يفهم الكلمات كلها كمحارف فإذا اختلفت هذه المحارف ولو اختلافا بسيطاً اعتبرها الحاسوب كلمة مختلفة  تماماً.  ستسمي هذه المرحلة في معالجة اللغات الطبيعية إيجاد أصل الكلمة أي اكتشاف الشكل  الأساسي Lemma" لكل كلمة في الجملة.  تطبق عملية إيجاد أصل الكلمة على الأفعال والأسماء. فنحن نعلم أن الأفعال تتغير أشكالها  بتغير الزمن الذي تدل عليه أو حسب الضمائر المتصلة بها.  عادة يتم الاعتماد على جدول مفهرس لأشكال الكلمات وأصلها بناء على قسمها الكلامي من أجل عملية إيجاد أصل الكلمة، ويمكن أن يكون هناك قواعد مخصصة للكلمات التي لا ترد كثيرا، وتعتبر خوارزميات إيجاد أصل الكلمة مجالاً مفتوحاً للبحث العلمي. مثال يوضح عملية الحصول على أصل الكلمة  تعتبر  دمشق  اعتبر  "تمتق"  العواصم  المأهولة  العالم  "عاصمة  "مأهول"  "عالم" 
            المرحلة الخامسة تحديد كلمات التوقف :  
            نريد الآن أن نفكر بأهمية كل كلمة في الجملة، ففي أغلب اللغات تتكرر حروف العطف والتعريف كثيرا خلال الجمل النصية. وعند بناء نماذج إحصائية للغة ستعطي هذه الكلمات تشويشا للنتيجة حيث أنها تظهر أكثر من باقي الكلمات في الجمل. يمكن تسمية هذه الكلمات بكلمات التوقف Stop Words وهي الكلمات التي يجب حذفها من النص قبل البدء بأي عملية إحصائية تصبح الجملة المدروسة بالشكل التالي بعد إزالة حروف التوقف تعتبر مدينة دمشق  أقدم العواصم المأهولة العالم".  يمكن تحديد حروف التوقف بإضافة سلسلة من كلمات التوقف المعروفة، لكن لا يوجد سلسلة قياسية لحروف التوقف مناسبة لكل التطبيقات وذلك لأن كلمات التوقف تختلف من تطبيق  لآخر.  على سبيل المثال في اللغة الإنجليزية ، إذا كنت تقوم بإنشاء محرك بحث الموسيقى الروك ، فأنت تريد التأكد من أنك لا تتجاهل كلمة " The". وذلك لأنه لا تظهر كلمة "The" في أسماء مجالات الموسيقى فقط، فهناك أيضا فرقة روك شهيرة من ثمانينيات القرن العشرين تسمى  The The 
            المرحلة السادسة: ا الإعراب الاعتمادي Dependency Parsing
            عزيزي القارئ لعلك مللت من كثرة الخطوات، إنها لغة طبيعية ومعالجتها ليست بالأمر السهل فنحن نحاول أن تجعل الحاسوب الآلة- الجامدة تقرأ لغتنا وتفهم معانيها. في هذه المرحلة سنكتشف علاقات كلمات الجملة مع بعضها البعض وهذا ما يسمى الإعراب الاعتمادي. تتميز اللغة العربية بنظام إعرابي خاص بها كونها لغة غنية بالمكونات النحوية، فمثلا لتكن لدينا الجملة الثانية: صديقي ولد في دمشق" يمكن أن تكون الهيئات التركيبية للجملة – أي ترتيب المكونات النحوية التي تتألف منها الجملة كما يلي: 
            الهيئات التركيبية للجملة "صديقي ولد في دمشق"
            سنأخذ الجملة التالية تعتبر دمشق من أقدم العواصم المأهولة في العالم، وهي عاصمة سورية"
            الهدف من مرحلة الإعراب الاعتمادي هو بناء شجرة تعيّن كلمة أصل واحدة لكل كلمة في الجملة. وسيكون جذر الشجرة هو الفعل الرئيسي في الجملة 
            توضح لنا هذه الشجرة التحليلية أن نائب الفاعل في الجملة هو الاسم "دمشق" وله علاقة تعتبر " مع "العواصم"، ونحن نعلم سابقا من مرحلة إيجاد أصل الكلمة أن أصل العواصم عاصمة"، وبالتالي علمنا شيئاً مفيداً وهو أن دمشق عاصمة وإذا تابعنا شجرة التحليل الكاملة لهذه الجملة، فستكتشف أن دمشق هي عاصمة سورية.  يعمل الإعراب الاعتمادي أيضا على تمرير الكلمات إلى نموذج التعلم الآلي وإخراج النتيجة تماما مثل الطريقة التي تنبأنا بها عن أقسام الكلام في المرحلة السابقة باستخدام نموذج التعلم الآلي ولكن الإعراب الاعتمادي مهمة معقدة بشكل خاص وتتطلب مقالات أخرى لشرحها بالتفصيل.  يمكن اعتبار هذا الأسلوب في الإعراب الاعتمادي هو طريقة قياسية لكن قد يجد البعض أنه أصبح قديماً، حيث أصدرت Google في عام ٢٠١٦ محللا جديدًا للإعراب يُدعى Parsey McParseface والذي تفوق على المعايير السابقة باستخدام منهج جديد للتعلم العميق انتشر سريعا في جميع الأنحاء. بعد ذلك بعام ، أطلقوا نموذجًا أحدث أطلق عليه اسم Parsey Saurus مما زاد من تحسين الأمور وبذلك يمكننا القول، أن تقنيات الإعراب لا تزال مجالا للبحث  العلمي.  ويصعب من المهم أن نتذكر أن اللغة العربية غنية بالمكونات النحوية وتحتاج إلى دراسة تحليلية تخصصية لمعرفة إعرابها الصحيح، وكذلك هناك عدة جمل إنجليزية غامضة تحليلها، وفي هذه الحالات، سيقدم النموذج تخمينا اعتمادا على ما يبدو إعراب الجملة ، لكنه ليس مثاليا وأحيانا سيكون النموذج خاطئا بشكل كبير. لذلك مع مرور الوقت، ستستمر نماذج معالجة اللغات الطبيعية في تحسين إعراب النص بطريقة مقبولة، على مستوى جميع اللغات ولا سيما اللغة العربية التي هي قيد البحث والتطوير.  ب: إيجاد العبارات الاسمية  حتى الآن، تعاملنا مع كل كلمة في الجملة ككيان منفصل. لكن في بعض الأحيان يكون من المنطقي تجميع الكلمات التي تمثل فكرة أو شيء واحد معا. يمكننا استخدام المعلومات من شجرة الإعراب الاعتمادي لتجميع الكلمات التي تتحدث عن نفس الشيء تلقائيا.  على سبيل المثل بدلاً من هذا الشكل  تعتبر دمشق من أقدم العواصم المأهولة في العالم فعل نائب فاطل جار ومجرور مضاف إليه  جار ومجرور  يمكننا تجميع الكلمات التي وقعت في محل جر وعبرت عن فكرة واحدة، لتوليد ذلك الشكل:  تعتبر دمشق من أقدم العواصم المأهولة في العالم  قالب فاعل  الأسماء التي وقعت في محل جر وعبرت عن وصف لدمشق  العبارات الاسمية
            إن هذه المرحلة اختيارية وذلك بناء على الهدف المطلوب. وغالبا تكون هذه المرحلة طريقة سريعة وسهلة لتبسيط الجملة إذا لم نكن بحاجة إلى المزيد من التفاصيل.

            المرحلة السابعة: التعرف على الكيانات المسماة Named-Entity Recognition NER بعد أن أنهينا القسم الصعب، الذي كان يهتم بالقواعد، تنتقل إلى استخراج الأفكار من الجمل.
            تشير بعض هذه الأسماء على أشياء من الواقع مثلا دمشق ، سورية لها مواقع جغرافية على الخريطة يمكنك تحديدها. وبذلك سنقوم بالاستخراج الآلي للائحة من الأماكن الحقيقية المذكورة في المستند النص باستخدام معالجة اللغات الطبيعية.
            الهدف من التعرف على الكيانات المسماة هو تحديد وتسمية label هذه الأسماء Nouns
            بمفاهيم حقيقية تمثلها
            التعرف علي الكيانات المسماة Namad Entity Recognition :
            أنظمة التعرف على الكيانات المسماة لا تقتصر مهمتها على إنجاز قاموس بسيط فحسب، إنما تستخدم سياق الكلام لتعرف كيفية ظهور الكلمة والنموذج الإحصائي للتنبؤ بنوع الاسم الذي
            تمثله الكلمة فنظام التعرف على الكيانات المسماة الجيد يستطيع تمييز "شام" (اسم لفتاة) أنها شخص وشام" مكان ذو موقع جغرافي وذلك من السياق.
            ستورد لكم بعض الأشياء التي تستطيع أنظمة التعرف على الكيانات المسماة تسميتها.
            . أسماء الأشخاص
            أسماء الشركات. .
            المواقع الجغرافية (الفيزيائية والسياسية)
            . التاريخ والوقت
            كميات النقود
            . أسماء الأحداث.
            إن التعرف على الكيانات المسماة له الكثير من الاستخدامات لأنه يستهل كثيرا عملية الحصول
            على البيانات المنظمة من النص، والوصول إلى فهمه .

            المرحلة الثامنة: القرار الجوهري Coreference Resolution :
            عند هذه المرحلة نكون قد أوجدنا التمثيل المفيد للجمل، من أجل كل جملة تعرف أقسام الكلام لكل كلمة كيفية ارتباط الكلمات مع بعضها والكلمات التي تمثل كيانات مسماة . 
            لكننا ما زلنا نعاني من مشكلة أخرى، فأغلب اللغات الطبيعية مليئة بالضمائر لأنها تستخدم لتختصر تكرار بعض الكلمات وتستطيع البشر أن تتبع سياق النص لتعرف على ماذا يدل كل ضمير في الجمل. لكن نماذج معالجة اللغات الطبيعية التي تتعامل مع كل جملة على حدا لن
            تستطيع أن تعرف دلالة الضمائر.
            فإذا نظرنا إلى الجملة التالية:
            "مدينة دمشق هي عاصمة الجمهورية العربية السورية وهي من أقدم العواصم المأهولة في
            العالم، وقد أسسها الأشوريون"
            إذا عالجنا هذه الجملة بالخطوات المتسلسلة لمعالجة اللغات الطبيعية سنعرف أن "هي" من أقدم العواصم لكن من المفيد والمهم أن نعرف أن "دمشق" من أقدم العواصم. يستطيع البشر ببساطة اكتشاف أن "هي" تعني "دمشق". إن الهدف من هذه المرحلة هو تمكين الحاسوب من إنجاز هذا التبع تتبع الضمائر عبر الجمل، ومعرفة كل الكلمات التي تشير إلى نفس الكيان نلاحظ نتيجة تنفيذ المقطع النصي على مرحلة القرار الجوهري.
            "مدينة دمشق هي عاصمة الجمهورية العربية السورية وهي من أقدم العواصم المأهولة في والآن سنكون قادرين على استخراج الكثير من المعلومات من النص نتيجة دمج المعلومات الجوهرية مع شجرة الإعراب ومعلومات الكيانات المسماة. إن القرار الجوهري هو أحد الخطوات الصعبة في تسلسل خطوات تطبيق معالجة اللغات الطبيعية، حتى أنها أكثر صعوبة من الإعراب الاعتمادي للجمل ولقد أدت التطورات الحديثة
            العالم، وقد أسسها الأشوريون"
            في التعلم العميق إلى مناهج جديدة أكثر دقة، لكنها ما زالت قيد الدراسات والأبحاث العلمية.
            المدخل
            الحصول على الكلمات
            اصل الكلام
            الإعراب الاعتمادي
            العبارات التعرف الاسمية
            الكيانات
            القرار الجوهري
            الخرج البيانات المهيكلة التي تمثل تفسير النص
            أسماء المنتجات

        `,
    },
    {
        "id":4,
        "type": "ques",
        "ques": [
            {
                "id": 0,
                "ques": "ماهي معالجة اللغة الطبيعيه NLP؟",
                "answer": "هى العلم الذي يجمع بين اللغة وعدد من مجالات علم الحاسب الآلى مثل : تعلم الآلة ، التعلم العميق،الشبكات العصبية الصناعية .",
                "key": ["إجابة", "الأول"],
                "notes": "معالجة اللغة الطبيعيه هى العلم الذي يجمع بين اللغة وعدد من مجالات علم الحاسب الآلى مثل : تعلم الآلة ، التعلم العميق،الشبكات العصبية الصناعية ."
            },
            {
                "id": 1,
                "ques": "اذكر أهمية برمجيات معالجة اللغات الطبيعية ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "تجعل الحوار بين الإنسان والآلة ممكنا بلغة اقرب ما تكون إلى اللغات الطبيعية التى يستخدمها فى الحوار مع أقرانه باستخدام الذكاء الاصطناعي ."
            },
            {
                "id": 2,
                "ques": "عرف المعالجة الآلية للغات الإنسانية ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "هو مجال فرعى يتبع الذكاء الاصطناعي و اللغويات الحاسوبية ويعنى بدراسة مشكلات التوليد والفهم الآلى للغات الإنسانية الطبيعية وتهدف انظمة توليد اللغات الطبيعية إلى تحويل البيانات والمعلومات المخزنة في قواعد بيانات الحاسب إلى لغة بشرية تبدو طبيعية ."
            },
            {
                "id": 3,
                "ques": "اذكر استخدامات تقنية معالجة اللغة الطبيعية ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "محركات البحث ، انظمة الكتابة ، تصحيح الأخطاء فى لوحات كتابة الهواتف المحمولة ، البحث الطبى ، مجالات المال والاعمال والبحث الأكاديمي ."
            },
            {
                "id": 4,
                "ques": "قارن بين اللغة الطبيعية واللغه الاصطناعية ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "اللغة الطبيعية هى اللغات البشرية كالعربية والإنجليزية التى نشأت وتطورت بدون تخطيط أو قواعد موضوعة مسبقا ولديها العديد من اللهجات المحلية والعامية المختلفة كما أنها تتطور تلقائيا ولذا تتطلب تحديثا فى استخراج قواعدها مع مرور الوقت ."
            },
            {
                "id": 5,
                "ques": "اذكر الأهداف المعالجة الآلية للغات الإنسانية ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "تواصل افضل مع الحاسب ."
            },
            {
                "id": 6,
                "ques": "ما هى اسباب الاهتمام بمعالجة اللغات الطبيعية ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "التطور الهائل فى علوم اللغويات و خضوعها للمعالجة الرياضية والمنطقية "
            },
            {
                "id": 7,
                "ques": "اذكر انواع معالجة اللغة الطبيعية NLP ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "توليد اللغة الطبيعية وهى التقنية التى تتيح للآلة بأن تستطيع توليد محتوى سواء نصي أو صوتى يشابه الذى قد يولده الإنسان العادى اي ان هذه التقنية تتعامل مع الآلة مع اللغة على أنها مخرجات لا مدخلات ."
            },
            {
                "id": 8,
                "ques": "اذكر تطبيقات معالجة اللغة الطبيعية ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "التعرف على الكلام ."
            },
            {
                "id": 9,
                "ques": "اذكر التقنيات الفرعية لتصنيف النصوص  ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "تصنيف الموضوعات ."
            },
            {
                "id": 10,
                "ques": "تكلم عن كيفيه استخلاص الكلمات المفتاحيه؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "تقوم هذه التقنيه بشكل اتوماتيكي ان تقوم باستخلاص اهم الكلمات المفتاحيه والتعبيرات في نص او مجموعة من النصوص ويتم استخدام هذه التقنيه بكثره في محركات البحث"
            },
            {
                "id": 11,
                "ques": "في ماتستخدم تطبيقات الترجمه الالية ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "المساعده على الفهم"
            },
            {
                "id": 12,
                "ques": "كيفيه استخدام تطبيق التعرف الضوئي على الحروف ؟",
                "answer": "هى العلم الذي يجمع بين اللغة وعدد من مجالات علم الحاسب الآلى مثل : تعلم الآلة ، التعلم العميق،الشبكات العصبية الصناعية .",
                "key": ["إجابة", "الأول"],
                "notes": "وذلك من خلال بعض التعديلات المتطورة حيث بلغت مكانه كبيره في شأوا في اللغات اللاتينية وفي اللغه العربيه أيضا وغير انها باهظه التكلفه وقليله الانتشار ومازلت مجال للبحث النشط سواء في اللغات اللاتينية او العربيه"
            },
            {
                "id": 13,
                "ques": "كيف يتم تحويل النص الي كلام منطوق؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "تتم ذلك من خلال قراءه النصوص او تحويل الكلام المكتوب الي صوت مسموع وكلام منطوق مفهوم وبذلك يسمى بنظام الحاسب او مؤلف الكلام وتحويل الكلام العادي الي لغه منها الرموز اللغويه الصوتيه الي كلام محزن في قاعده البيانات ويمكن معرفته في نموذج جهاز النطق ومعرفه الكلمه المراده"
            },
            {
                "id": 14,
                "ques": "اذكر بعض من التطبيقات التي يتم في معالجه النصوص؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "التطبيقات الطبيه الحيوية"
            },
            {
                "id": 15,
                "ques": "كيفيه الاستفاده من التطبيقات التسوقيه؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "يتم الاستفاده منها من خلال التعرف على طبيعه علاقه الشركات بعملائهم او ارائهم وانطباعهم حول منتجات وخدمات الشركات"
            },
            {
                "id": 16,
                "ques": "من أحدي مجالات معالجه اللغه الطبيعيه الرعايه الصحيه كيف تتم ذلك ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "وذلك من خلال استخدام معالجه اللغه الطبيعيه لتحليل والحصول على رؤي جديده في السجلات الصحيه والاهتمام بيها"
            },
            {
                "id": 17,
                "ques": "ماهو تطبيق المحادثات وكيف يتم؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "هو َواحد من أكثر التطبيقات معالجه اللغه الطبيعيه شهره حيث من خلال الخوارزميات الذكيه يمكنك بسهوله توفير ذكاء اصطناعي يرد على عملائك بذكاء بشري كما يمكن توفير انظمه خبراء قادره علي الاجابه على جميع الاسئله الموجودة"
            },
            {
                "id": 18,
                "ques": "كيفيه استخلاص الأسماء ذات الدلالات التي هي من أحدي تطبيقات لمعالجة النصوص؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "وذلك ان هذه التقنيه لا يمكن الاستغناء عنها لأنها هامه جدا اذا انها تجعل الاله قادره على التجاوب بشكل أفضل مع اللغه الطبيعيه حيث انها تسطيع استخلاص الكلمات المقصوده بها دلالات أخرى مثل ان تكون اسم لشخص مشهور او اسم فليم او مكان أو مسلسل وهكذا"
            },
            {
                "id": 19,
                "ques": "كيفيه تحليل المشاعر وكيف تتم ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "تحليل المشاعر هي واحده من أشهر تقنيات الNlp وأن هذه التقنيه تحاول فهم المشاعر التي تكمن وراء النصوص وتحدد الموافق الناتجه عنها سواء كانت معينه او حيره او سخريه وماالي ذلك وتعمل هذه الخاصيه على الرد التلقائي على العملاء والمدح والشاوي وغير ذلك بالطرق المناسبه حسب الأوامر المحدده من قبل الشركه"
            },
            {
                "id": 20,
                "ques": "كيفية تصنيف أقسام الكلام ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "استخراج اقسام الكلام من النص (اقسام الكلام مثل فعل ماض، فعل مضارع، فعل امر، صفه، اسم حال) فيتم تصنيف كل كلمه في النص الي القسم الذي يمثلها "
            },
            {
                "id": 21,
                "ques": "ما هوا فك التباس معني الكلمات WSD ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "هو استخلاص المعني الصحيح من الكلمه وفقا للسياق  ويتطلب استخدام خورزميات محدده من اجل معالجعة المشاكل  "
            },
            {
                "id": 22,
                "ques": "كيفية استخدام معالجة البيانات ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "تقوم برمجيات معالجة اللغات الطبيعية NLP باستخدام المعالجة المسبقة مثل الترميز،  وتحديد الجذر اللغوي، والتصرف، واستبعاد كلمات التوقف لتجهيز البيانات لمختلف التطبيقات "
            },
            {
                "id": 23,
                "ques": "ما التحديات التي تواجه معالجة اللغة الطبيعية NLP ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes":" الدقة و اللهجات واللغات العامية و مشاكل تقسيم الجمل"
                
            },
            {
                "id": 24,
                "ques": "ما التي تحتويه اللهجات  الطبيعية واللغات العامية ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "اللغات الطبيعية تحتوي علي الكثير من اللهجات، فاللغة العربية الخاصة بنا تنقسم لمئات اللهجات المحلية وهناك اللهجة السعودية واللهجة التونسيه وغيرها من اللغات العربيه لذا فإن العلماء يركزون علي اللغات الفصحي "
            },
            {
                "id": 25,
                "ques": "ما الطريقة التي تفهم بها الألة الجملة ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "نحن كبشر نستخدم التعبيرات المجازيّة في احاديثنا اليومية، والتي نستطيع نحن البشر فهمها والتعامل معها، والرد بالردود المناسبه."
            },
            {
                "id": 26,
                "ques": "ما هيا خطوات تنفيذ معالجة اللغات الطبيعية NPL ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "في المعتاد، تبدا عملية معالجة اللغات الطبيعية(NPL) بجمع وإعداد بيانات نصيه او كلامية غير مهيكلة من مصادر مثل مستودعات البيانات السحابية او تطبيقات عمليات الأعمال الداخلية او رسائل البريد الإلكتروني"
            },
            {
                "id": 27,
                "ques": "ما هيا المهام المطلوبة لمعالجة اللغات الطبيعية (NPL) ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "فيها تساعد الكمبيوتر في فهم كيفية تكون الكلمات  علاقات ذات المعني مع بعضها البعض"
            },
            {
                "id": 28,
                "ques": "ما هيا طرق معالجة اللغة الطبيعية الخاضعة للإشراف؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "تقوم معالجة اللغة الطبيعية الخاضعة للإشراف بتدريب البرنامج بمجموعه من المدخلات والمخرجات  المعروفة. ويقوم البرنامج اولا بمعالجة كميات كبيرة من البيانات ويتعلم كيفية انتاج المخرجات الصحيحة من اي ادخال غير معروف.  "
            },
            {
                "id": 29,
                "ques": "ما هيا طرق معالجة اللغة الطبيعية غير الخاضعة للإشراف ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "تستخدم معالجة اللغة الطبيعية غير خاضعة للإشراف نموذج لغة إحصائية للتنبؤ  بالنمط الذي يحدث عندما يتم تغذيته بواسطة مدخلات غير مسماه."
            },
            {
                "id": 30,
                "ques": "ما هيا الاتجاهات الرئيسية لمعالجة اللغات الطبيعيه؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "المنهج المختلط القائم علي المنهجين اللغوي والإحصائي"
            },
            {
                "id": 31,
                "ques": "ما هي الاساليب اللغويه المعتمده علي القواعد ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "المنهج القاعدي اساليب متعلقه بمهام التعرف علي كيانات الاسماء مثل الأساليب المستخدمه في نظام استخراج المعلومات ANNIE الخاص بمناصة GATE"
            },
            {
                "id": 32,
                "ques": "ما هي مجالات استخدام المكانز ؟",
                "answer": "هى العلم الذي يجمع بين اللغة وعدد من مجالات علم الحاسب الآلى مثل : تعلم الآلة ، التعلم العميق،الشبكات العصبية الصناعية .",
                "key": ["إجابة", "الأول"],
                "notes": "تساعد المكانز اللغويه علي معرفة معلومات غاية في الاهميه لبناء المعجم وهيا متابعة الكلمات الجديدة التي تدخل اللغه وتحديد وقت دخولها."
            },
            {
                "id": 33,
                "ques": "اهمية المكانز اللغوية في بناء معجم بالغه العربية ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "حصر جميع المعاني: من مميزات البحث الألكترونيّ في المكانز اللغويه امكانية عرض جميع السياقات التي يمكن ان تظهر فيها الكلمه"
            },
            {
                "id": 34,
                "ques": "ما هيا المتصاحبات اللغويه والتعبيرات الاصلاحية ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "هوا تركيب لغوي تؤدي كلماته مجتمعه معني لا صله له بمعني كل كلمه مفرده وهوا تعبير لا يقبل بالغير بين كلماته استبدالا او تقديما او تاخيرا او حذفا او غير ذلك من اشكال التغيير"
            },
            {
                "id": 35,
                "ques": "كيف تم وضع قواعد اللغة العربية ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "قاعدة رفع الفاعل ونصب المفعول وجر المضاف اليه جاءت من دراسة  ابيات الشعر والقرانوالأحديث "
            },
            {
                "id": 36,
                "ques": "ما هي مستويات تحليل اللغات الطبيعية ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "التحليل المصرفي"
            },
            {
                "id": 37,
                "ques": "ما هوا التحليل الصرفي وكيف يهتم بمعرفة نوع الكلمات ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "هوا تحليل يهتم بمعرفة ضمائر الكلمات وغيرها من المعلومات المصرفيه كتحديد هل هيا جمع ام مفرد صيغة تذكير ام تأنيب صيغة ماضي ام مضارع بالإضافة الي تحديد اصل الكلمه والزوائد الداخلية عليها"
            },
            {
                "id": 38,
                "ques": "ما المنهجيات المتابعه في المعالجة اللغويه في اللغه العربيه ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "هناك نوعان رئيسان احدهما منهجيه قائمه علي المعرفه والأخري منهجيه مبنيه علي التعلم  المنهجيه القائمه علي المعرفه هيا قواعد مكتوبه يدويا وتجري كتابة هذة القواعد عادة علي يد متخصصين ومن بين مزاياها الكبيره السهوله الكبيره في الفهم النتائج "
            },
        ],
    },
    {
        "id":5,
        "type": "lesson",
        "title": "الدرس الاول",
        "video": "https://res.cloudinary.com/dtxava86t/video/upload/v1683583187/video/lesson5.mp4",
        "sub-title": "مراحل معالجة النصوص NLP",
        "desc": `
            المرحلة الأولى: تجزئة الجمل Sentence Segmentation
            إن المرحلة الأولى في مراحل معالجة اللغات الطبيعية هي تقطيع النص إلى الجمل المكون منها، فمن النص السابق المدروس تكون الجمل: كل جملة من جمل النص تعبر عن فكرة معينة كما هو الأمر بالنسبة لأي نص في اللغة الطبيعية، لذلك يكون من الأسهل أن نجعل الحاسوب يفهم فكرة جملة إلى أن يصل إلى فهم كامل النص المؤلف من هذه الجمل. ومن الشائع في تقطيع النصوص الاعتماد على علامات التنقيط حيث تشكل علامات التنقيط الفاصل بين جمل النص، وفي حال لم يكن النص منسقا باستخدام علامات التنقيط فيمكن اعتماد طرق أكثر تعقيدا لتقطيع النص والحصول على جمله.

            المرحلة الثانية: الحصول على الوحدات اللغوية Tokenization
            في المرحلة الثانية سنقوم بتقطيع الجمل التي حصلنا عليها إلى الوحدات اللغوية Tokens ، في حالتنا تتمثل token بالكلمة word ، ويمكن أن تتم هذه المرحلة من المعالجة على التسلسل أي معالجة جملة تلو الجملة الأخرى.
            لنأخذ الجملة الأولى من النص المدروس على سبيل المثال مدينة دمشق هي عاصمة الجمهورية العربية السورية و أكبر المدن السورية من حيث الكثافة السكانية" تتمثل هذه المرحلة التي تدعى Tokenization الحصول على الوحدات اللغوية) بتقطيع الجمل إلى كلماتها، فإذا طبقنا عملية الحصول على الوحدات اللغوية على الجملة المدروسة ستحصل على الكلمات التالية:
            مدينة "دمشق"، "هي"، "عاصمة الجمهورية"، " العربية"، "السورية"، "و" أكبر"، "المدن"، "السورية"، "من"، "حيث"، "الكثافة"، "السكانية"، "". إن عملية الحصول على الكلمات في اللغة الإنجليزية بسيط لأنه يمكن أن يكون الفراغ هو الفاصل بين كلمات الجمل أما بالنسبة إلى اللغة العربية فالأمر أكثر تعقيدا، لوجود ضمائر متصلة بالكلمة وكل ضمير يحمل معنى مختلفاً تفصل علامات التنقيط كوحدة لغوية Token مستقلة، وذلك لأننا نعرف أن كل علامة تنقيط لها معنى مختلف عن الأخرى.

            المرحلة الثالثة: التنبؤ بأقسام الكلام  
            ستقوم في هذه المرحلة بإسناد كل وحدة لغوية إلى قسم الكلام المناسب لها سواء كان أسماء أو "مدينة"، "دمشق"، "هي"، "عاصمة الجمهورية"، " العربية"، "السورية"، "و"، أكبر"، "المدن"، "السورية"، "من"، "حيث"، الكثافة"، "السكانية"، ".".  إن عملية الحصول على الكلمات في اللغة الإنجليزية بسيط لأنه يمكن أن يكون الفراغ هو الفاصل بين كلمات الجمل أما بالنسبة إلى اللغة العربية فالأمر أكثر تعقيداً، لوجود ضمائر متصلة بالكلمة وكل ضمير يحمل معنى مختلفا. سنقوم في هذه المرحلة بإسناد كل وحدة لغوية إلى قسم الكلام المناسب لها سواء كان أسماء أو فعلا أو صفة.  تفصل علامات التنقيط كوحدة لغوية Token ،مستقلة، وذلك لأننا نعرف أن كل علامة تنقيط لها معنى مختلف عن الأخرى.   موسومة tagged  لنأخذ باعتبارنا أن النموذج يعتمد بشكل كلي على الإحصاءات ومهما كانت نتائجهم صحيحة لكنه بالتأكيد لن يفهم ماذا تعني الكلمات في الحقيقة كما نفهمها نحن كبشر. إن النموذج يعرف فقط كيف يتنبأ بأقسام الكلام بناء على الجمل والكلمات التي مررت له سابقاً. بعد معالجة الجملة التالية تعتبر مدينة دمشق من أقدم العواصم المأهولة في العالم" يمكن أن نحصل على النتيجة التالية:  دمشق  "فعل"  اسم علم"  حرف جر  اسم  العواصم  المأهولة  العالم  "اسم"  اسم "  حرف  اسم"  عند حصولنا على هذه المعلومات، ستستطيع البدء بجمع المعاني الأساسية، على سبيل المثال بعد معرفتنا أن الأسماء تضم "دمشق" و "العواصم" فإن الجملة ربما تتحدث عن دمشق. 
            المرحلة الرابعة أصل كلمات  النص  Lematization  تظهر الكلمة في اللغات الطبيعية بأشكال مختلفة ، مثلا في اللغة الإنجليزية يضاف حرف 8 إلى آخر بعض الكلمات لتعبر عن الجمع، أما في اللغة العربية فتضاف بعض الحروف وتحذف بعضها لتعبر عن حالات مختلفة في علم الصرف للغة العربية، وأصل الكلمة هو الشكل الأساسي لها على سبيل المثال فإن الشكل الأساسي لكلمة يحتاجون" في اللغة العربية هي احتاج" وكذلك الشكل الأساسي لكلمة "studied" في اللغة الإنكليزية "study".  ومن المفيد أن يعرف الحاسوب أصل الكلمات أي شكلها الأساسي كي يعرف أن الجمل التي تحتوي هذه الكلمات تدل على مفهوم واحد. فكما تعلم عزيزي القارئ أن الحاسوب يفهم الكلمات كلها كمعارف فإذا اختلفت هذه المحارف ولو اختلافا بسيطا اعتبرها الحاسوب كلمة مختلفة  Lematization  تظهر الكلمة في اللغات الطبيعية بأشكال مختلفة ، مثلا في اللغة الإنجليزية يضاف حرف و إلى آخر بعض الكلمات لتعبر عن الجمع، أما في اللغة العربية فتضاف بعض الحروف وتحذف بعضها لتعبر عن حالات مختلفة في علم الصرف للغة العربية، وأصل الكلمة هو الشكل الأساسي لها على سبيل المثال فإن الشكل الأساسي لكلمة يحتاجون" في اللغة العربية هي احتاج" وكذلك الشكل الأساسي لكلمة studied في اللغة الإنكليزية "study.  ومن المفيد أن يعرف الحاسوب أصل الكلمات أي شكلها الأساسي كي يعرف أن الجمل التي تحتوي هذه الكلمات تدل على مفهوم واحد فكما تعلم عزيزي القارئ أن الحاسوب يفهم الكلمات كلها كمحارف فإذا اختلفت هذه المحارف ولو اختلافا بسيطاً اعتبرها الحاسوب كلمة مختلفة  تماماً.  ستسمي هذه المرحلة في معالجة اللغات الطبيعية إيجاد أصل الكلمة أي اكتشاف الشكل  الأساسي Lemma" لكل كلمة في الجملة.  تطبق عملية إيجاد أصل الكلمة على الأفعال والأسماء. فنحن نعلم أن الأفعال تتغير أشكالها  بتغير الزمن الذي تدل عليه أو حسب الضمائر المتصلة بها.  عادة يتم الاعتماد على جدول مفهرس لأشكال الكلمات وأصلها بناء على قسمها الكلامي من أجل عملية إيجاد أصل الكلمة، ويمكن أن يكون هناك قواعد مخصصة للكلمات التي لا ترد كثيرا، وتعتبر خوارزميات إيجاد أصل الكلمة مجالاً مفتوحاً للبحث العلمي. مثال يوضح عملية الحصول على أصل الكلمة  تعتبر  دمشق  اعتبر  "تمتق"  العواصم  المأهولة  العالم  "عاصمة  "مأهول"  "عالم" 
            المرحلة الخامسة تحديد كلمات التوقف :  
            نريد الآن أن نفكر بأهمية كل كلمة في الجملة، ففي أغلب اللغات تتكرر حروف العطف والتعريف كثيرا خلال الجمل النصية. وعند بناء نماذج إحصائية للغة ستعطي هذه الكلمات تشويشا للنتيجة حيث أنها تظهر أكثر من باقي الكلمات في الجمل. يمكن تسمية هذه الكلمات بكلمات التوقف Stop Words وهي الكلمات التي يجب حذفها من النص قبل البدء بأي عملية إحصائية تصبح الجملة المدروسة بالشكل التالي بعد إزالة حروف التوقف تعتبر مدينة دمشق  أقدم العواصم المأهولة العالم".  يمكن تحديد حروف التوقف بإضافة سلسلة من كلمات التوقف المعروفة، لكن لا يوجد سلسلة قياسية لحروف التوقف مناسبة لكل التطبيقات وذلك لأن كلمات التوقف تختلف من تطبيق  لآخر.  على سبيل المثال في اللغة الإنجليزية ، إذا كنت تقوم بإنشاء محرك بحث الموسيقى الروك ، فأنت تريد التأكد من أنك لا تتجاهل كلمة " The". وذلك لأنه لا تظهر كلمة "The" في أسماء مجالات الموسيقى فقط، فهناك أيضا فرقة روك شهيرة من ثمانينيات القرن العشرين تسمى  The The 
            المرحلة السادسة: ا الإعراب الاعتمادي Dependency Parsing
            عزيزي القارئ لعلك مللت من كثرة الخطوات، إنها لغة طبيعية ومعالجتها ليست بالأمر السهل فنحن نحاول أن تجعل الحاسوب الآلة- الجامدة تقرأ لغتنا وتفهم معانيها. في هذه المرحلة سنكتشف علاقات كلمات الجملة مع بعضها البعض وهذا ما يسمى الإعراب الاعتمادي. تتميز اللغة العربية بنظام إعرابي خاص بها كونها لغة غنية بالمكونات النحوية، فمثلا لتكن لدينا الجملة الثانية: صديقي ولد في دمشق" يمكن أن تكون الهيئات التركيبية للجملة – أي ترتيب المكونات النحوية التي تتألف منها الجملة كما يلي: 
            الهيئات التركيبية للجملة "صديقي ولد في دمشق"
            سنأخذ الجملة التالية تعتبر دمشق من أقدم العواصم المأهولة في العالم، وهي عاصمة سورية"
            الهدف من مرحلة الإعراب الاعتمادي هو بناء شجرة تعيّن كلمة أصل واحدة لكل كلمة في الجملة. وسيكون جذر الشجرة هو الفعل الرئيسي في الجملة 
            توضح لنا هذه الشجرة التحليلية أن نائب الفاعل في الجملة هو الاسم "دمشق" وله علاقة تعتبر " مع "العواصم"، ونحن نعلم سابقا من مرحلة إيجاد أصل الكلمة أن أصل العواصم عاصمة"، وبالتالي علمنا شيئاً مفيداً وهو أن دمشق عاصمة وإذا تابعنا شجرة التحليل الكاملة لهذه الجملة، فستكتشف أن دمشق هي عاصمة سورية.  يعمل الإعراب الاعتمادي أيضا على تمرير الكلمات إلى نموذج التعلم الآلي وإخراج النتيجة تماما مثل الطريقة التي تنبأنا بها عن أقسام الكلام في المرحلة السابقة باستخدام نموذج التعلم الآلي ولكن الإعراب الاعتمادي مهمة معقدة بشكل خاص وتتطلب مقالات أخرى لشرحها بالتفصيل.  يمكن اعتبار هذا الأسلوب في الإعراب الاعتمادي هو طريقة قياسية لكن قد يجد البعض أنه أصبح قديماً، حيث أصدرت Google في عام ٢٠١٦ محللا جديدًا للإعراب يُدعى Parsey McParseface والذي تفوق على المعايير السابقة باستخدام منهج جديد للتعلم العميق انتشر سريعا في جميع الأنحاء. بعد ذلك بعام ، أطلقوا نموذجًا أحدث أطلق عليه اسم Parsey Saurus مما زاد من تحسين الأمور وبذلك يمكننا القول، أن تقنيات الإعراب لا تزال مجالا للبحث  العلمي.  ويصعب من المهم أن نتذكر أن اللغة العربية غنية بالمكونات النحوية وتحتاج إلى دراسة تحليلية تخصصية لمعرفة إعرابها الصحيح، وكذلك هناك عدة جمل إنجليزية غامضة تحليلها، وفي هذه الحالات، سيقدم النموذج تخمينا اعتمادا على ما يبدو إعراب الجملة ، لكنه ليس مثاليا وأحيانا سيكون النموذج خاطئا بشكل كبير. لذلك مع مرور الوقت، ستستمر نماذج معالجة اللغات الطبيعية في تحسين إعراب النص بطريقة مقبولة، على مستوى جميع اللغات ولا سيما اللغة العربية التي هي قيد البحث والتطوير.  ب: إيجاد العبارات الاسمية  حتى الآن، تعاملنا مع كل كلمة في الجملة ككيان منفصل. لكن في بعض الأحيان يكون من المنطقي تجميع الكلمات التي تمثل فكرة أو شيء واحد معا. يمكننا استخدام المعلومات من شجرة الإعراب الاعتمادي لتجميع الكلمات التي تتحدث عن نفس الشيء تلقائيا.  على سبيل المثل بدلاً من هذا الشكل  تعتبر دمشق من أقدم العواصم المأهولة في العالم فعل نائب فاطل جار ومجرور مضاف إليه  جار ومجرور  يمكننا تجميع الكلمات التي وقعت في محل جر وعبرت عن فكرة واحدة، لتوليد ذلك الشكل:  تعتبر دمشق من أقدم العواصم المأهولة في العالم  قالب فاعل  الأسماء التي وقعت في محل جر وعبرت عن وصف لدمشق  العبارات الاسمية
            إن هذه المرحلة اختيارية وذلك بناء على الهدف المطلوب. وغالبا تكون هذه المرحلة طريقة سريعة وسهلة لتبسيط الجملة إذا لم نكن بحاجة إلى المزيد من التفاصيل.

            المرحلة السابعة: التعرف على الكيانات المسماة Named-Entity Recognition NER بعد أن أنهينا القسم الصعب، الذي كان يهتم بالقواعد، تنتقل إلى استخراج الأفكار من الجمل.
            تشير بعض هذه الأسماء على أشياء من الواقع مثلا دمشق ، سورية لها مواقع جغرافية على الخريطة يمكنك تحديدها. وبذلك سنقوم بالاستخراج الآلي للائحة من الأماكن الحقيقية المذكورة في المستند النص باستخدام معالجة اللغات الطبيعية.
            الهدف من التعرف على الكيانات المسماة هو تحديد وتسمية label هذه الأسماء Nouns
            بمفاهيم حقيقية تمثلها
            التعرف علي الكيانات المسماة Namad Entity Recognition :
            أنظمة التعرف على الكيانات المسماة لا تقتصر مهمتها على إنجاز قاموس بسيط فحسب، إنما تستخدم سياق الكلام لتعرف كيفية ظهور الكلمة والنموذج الإحصائي للتنبؤ بنوع الاسم الذي
            تمثله الكلمة فنظام التعرف على الكيانات المسماة الجيد يستطيع تمييز "شام" (اسم لفتاة) أنها شخص وشام" مكان ذو موقع جغرافي وذلك من السياق.
            ستورد لكم بعض الأشياء التي تستطيع أنظمة التعرف على الكيانات المسماة تسميتها.
            . أسماء الأشخاص
            أسماء الشركات. .
            المواقع الجغرافية (الفيزيائية والسياسية)
            . التاريخ والوقت
            كميات النقود
            . أسماء الأحداث.
            إن التعرف على الكيانات المسماة له الكثير من الاستخدامات لأنه يستهل كثيرا عملية الحصول
            على البيانات المنظمة من النص، والوصول إلى فهمه .

            المرحلة الثامنة: القرار الجوهري Coreference Resolution :
            عند هذه المرحلة نكون قد أوجدنا التمثيل المفيد للجمل، من أجل كل جملة تعرف أقسام الكلام لكل كلمة كيفية ارتباط الكلمات مع بعضها والكلمات التي تمثل كيانات مسماة . 
            لكننا ما زلنا نعاني من مشكلة أخرى، فأغلب اللغات الطبيعية مليئة بالضمائر لأنها تستخدم لتختصر تكرار بعض الكلمات وتستطيع البشر أن تتبع سياق النص لتعرف على ماذا يدل كل ضمير في الجمل. لكن نماذج معالجة اللغات الطبيعية التي تتعامل مع كل جملة على حدا لن
            تستطيع أن تعرف دلالة الضمائر.
            فإذا نظرنا إلى الجملة التالية:
            "مدينة دمشق هي عاصمة الجمهورية العربية السورية وهي من أقدم العواصم المأهولة في
            العالم، وقد أسسها الأشوريون"
            إذا عالجنا هذه الجملة بالخطوات المتسلسلة لمعالجة اللغات الطبيعية سنعرف أن "هي" من أقدم العواصم لكن من المفيد والمهم أن نعرف أن "دمشق" من أقدم العواصم. يستطيع البشر ببساطة اكتشاف أن "هي" تعني "دمشق". إن الهدف من هذه المرحلة هو تمكين الحاسوب من إنجاز هذا التبع تتبع الضمائر عبر الجمل، ومعرفة كل الكلمات التي تشير إلى نفس الكيان نلاحظ نتيجة تنفيذ المقطع النصي على مرحلة القرار الجوهري.
            "مدينة دمشق هي عاصمة الجمهورية العربية السورية وهي من أقدم العواصم المأهولة في والآن سنكون قادرين على استخراج الكثير من المعلومات من النص نتيجة دمج المعلومات الجوهرية مع شجرة الإعراب ومعلومات الكيانات المسماة. إن القرار الجوهري هو أحد الخطوات الصعبة في تسلسل خطوات تطبيق معالجة اللغات الطبيعية، حتى أنها أكثر صعوبة من الإعراب الاعتمادي للجمل ولقد أدت التطورات الحديثة
            العالم، وقد أسسها الأشوريون"
            في التعلم العميق إلى مناهج جديدة أكثر دقة، لكنها ما زالت قيد الدراسات والأبحاث العلمية.
            المدخل
            الحصول على الكلمات
            اصل الكلام
            الإعراب الاعتمادي
            العبارات التعرف الاسمية
            الكيانات
            القرار الجوهري
            الخرج البيانات المهيكلة التي تمثل تفسير النص
            أسماء المنتجات

        `,
    },
    {
        "id": 6,
        "type": "lesson",
        "title": "الدرس الثانى",
        "video": "https://res.cloudinary.com/dtxava86t/video/upload/v1683583187/video/lesson6.mp4",
        "sub-title": "مراحل معالجةااللغات الطبيعية ",
        "desc": `
            ملاحظة قبل المتابعة تجدر الإشارة إلى أن هذه هي الخطوات في تسلسل معالجة اللغات الطبيعية نموذجية، فقد نتخطى بعض الخطوات أو نعيد ترتيب الخطوات اعتمادا على ما نريد القيام به وكيفية تنفيذ مكتبات معالجة اللغات الطبيعية على سبيل المثال، تقوم بعض المكتبات مثل Spacy بتنفيذ تجزئة الجمل بالاعتماد على نتيجة مرحلة الإعراب الاعتمادي .

            والآن لنفكر معا كيف يمكننا تنفيذ كل هذه الخطوات خطوات معالجة اللغات الطبيعية.
            
            إذا كنا نعمل على معالجة اللغة الإنجليزية فهناك عدة مكتبات بلغة البايثون متساعدنا في تنفيذ هذه الخطوات، أما إذا أردنا معالجة اللغة العربية فالأمر مختلف، لأن اللغة العربية ما زالت بحاجة إلى دعمكم أيها القراء والباحثون في هذا المجال، فأغلب المكتبات لم تدعم اللغة العربية
            
            بعد
            
            ما هي معالجه النصوص  (Text Analysis) ؟
            
            معالجة النصوص هي فرع من فروع معالجة اللغات الطبيعية Natural Language (Processing NLP ويعنى هذا الفرع بمعالجة اللغة المكتوبة بالذات. يشار إليها كذلك بتنقيب النصوص (Text Mining ، حيث تتمحور عمليات هذا الفرع من معالجة اللغات الطبيعية على أخذ النص الخام وتحويله إلى شكل يمكن للحاسب فهمه واستخلاص معلومات منه كيني منطقية أو بيانات مهيكلة.
            
            أو يمكن القول بأنها عملية استخلاص معلومات غير معروفة مسبقا من قبل الحاسب الآلي من خلال استخلاص المعلومات أليا من عدة مصادر مكتوبة. 
            
            تتشابه تقنيات معالجة النصوص (تنقيب النصوص) في الهدف النهائي مع المعلومات إلا أن استخلاص المعلومات غير محصور فقط باستخلاصها من النص المكتوب إذ يمكن استخلاص المعلومات من الصور والصوت وقواعد البيانات المهيكلة ... الخ.
            تحت مسمى معالجة النصوص تقع العديد من الخوارزميات التي تتنوع في آلية عملها ما بين خوارزميات إحصائية، تعلم عيق وخوارزميات لغوية.
            
            عمليات معالجة النصوص:-
            
            كانت النصوص حتى فترة قريبة من التاريخ هي المصدر الوحيد لتخزين المعلومات وتشاركها، ومازالت النصوص حاليا – رغم التنوع الكبير في الوسائط الممكن استخدامها لنقل المعلومات المصدر الأساسي لحفظ المعلومات بشتى أنواعها إضافة إلى أهميتها في التواصل مما يجعل عمليات استخلاص المعلومات من النصوص لانهائية بمقدار المعلومات الممكن حفلها فيها، فمن تحديد النصوص المتشابهة إلى تحديد توجه النص (إيجابي أو سلبي وصولاً لى التشخيص الآلي واستخلاص العناوين وغيرها الكثير.
            
            وتذكر بعضا من أشهر العمليات في معالجة النصوص :-
            ١-استرجاع المعلومات( Information retrieval IR) حيث يتم استخدام تقنيات معالجة النصوص للبحث والوصول إلى بيانات مكتوبة (كلمات) أو عبارات أو ما شابه معانيها من ديوان نصتي ما (corpus) على الانترنت أو في دواوين شخصية. 
            ٢-التعرف على الأعلام : Named entity recognition (NER) وهي عملية التعرف على الأسماء الأعلام للأشخاص والأماكن والمؤسسات ... ، واستخلاصها. 
            ٣-الإحالة المشتركة : (Coreference) وهي عملية التعرف على الكلمات والضمائر التي تشير إلى نفس الكينونة. 
            ٤-عتقدة النصوصDocument clustering) حيث يتم التعرف على النصوص المتشابهة وتجميعها معا.
            
            ٥-تحليل الآراء (Sentiment analysis) حيث يهدف هذا التحليل لتحديد المعاني الكامنة في النص وليس الحقائق، كاستكشاف المشاعر والتوجه في النص إيجابي سلبي أو مهين)
            ولكل واحدة من هذه العمليات استخداماتها المباشرة التي يمكن لك عزيزي القارئ تخيل بعضها، فمثلا عمليات التحليل الدلالي تستخدم مثلا في مواقع التواصل الاجتماعي للتعرف على التعليقات المهينة وحذفها، بينما استرجاع المعلومات تستخدم في محركات البحث ستركز في المقالات القادمة على تقنيات و خوارزميات تجميع النصوص المختلف بالذات.  
            لغات برمجة NLP :
            
            Python:
            
            تتوفر مكتبات NLP ومجموعات الأدوات بشكل عام في Python ، ولهذا السبب تم تطوير عالمية مشاريع NLP في Python تسهل بين التطوير التفاعلية لـ Python تطويرالتعليمات البرمجية الجديدة واختبارها. 
            
            : ++C و Java
            
            المعالجة كميات كبيرة من البيانات غالبًا ما يُفضل استخدام ++C و Java لأنها يمكن أن تدعم تعليمة برمجية أكثر كفاءة.
            المكتبات وبينات التطوير :
            
            فيما يلي أمثلة لبعض مكتبات NLP الشائعة .
            
            Tensor flow و PyTorchهاتان هما أكثر مجموعات أدوات التعلم العميق شيوعًا. وهي متاحة بحرية للأغراض البحثية والتجارية ولتن كانت تدعم لغات متعددة، فإن لغتهم الأساسية. هي Python فهي تأني مع مكتبات كبيرة من المكونات التي تم إنشاؤها مسبقاء لذا فعليا ما تتطلب نماذج معالجة اللغة الطبيعية المتطورة جذا توصيل هذه المكونات ببعضها البعض. كما أنها تدعم البنية الأساسية عالية الأداء للحوسبة، مثل مجموعات من الآلات المزودة بمسرعات وحدة معالجة رسومية.
            وجودات المحادثة البسيطة) التي يتم تنفيذها في Python PyTorch الوثائق ممتازة نسيق المختلفة التي تم تدريبها مسبقاء بالإضافة إلى مجموعة أدوات وامع التوصيل والشغل HuggingFace تقوم هذه الشركة بتوزيع مناك من نماذج معالجة اللغة التعليمية التعلم في TensorFlow و PyTorch التي تمكن المطورين من التقيم السريع لمدى جودة أداء المختلفة التي تم التدريب عليها في مهامهم المحددة. النماذج
            
            Allen Nlp هذه مكتبة من مكونات معالجة اللغة الطبيعية عالية المستوي ف على سبيل المثال روبوتات المحادثه البسيطه) التي يتم تنفيذها في البايثون الوثائق ممتازه.
            Huggingfaceتقوم هذه الشركه بتوزيع مئات من نماذج معالجه اللغه الطبيعيه للتعلم العميق المختلفه التي تم تدريبها مسبقا بالاضافه الي مجموعه ادوات برامج التوصيل والتشغيل في الpyTorchو Tensorflowالتي تمكن المطورين من التقييم السريع لمدي جوده اداء النماذج المختلفه التي تم التدريب عليها في مهامهم المحدده.  
            
            Spark NLP: Spark NLP هي مكتبة معالجة نصية مفتوحة المصدر لمعالجة اللغة الطبيعية المتقدمة للغات البرمجة Python و Scala Java هدفها هو توفير واجهة برمجة التطبيقات (API) لخطوط أنابيب معالجة اللغة الطبيعية وهو يقدم نماذج الشبكة العصبية المدربة وخطوط الأنابيب وحفلات الزفاف فضلا عن دعم تدريب اللعلاج المخصصة.
            
            SpaCy معالجة اللغة الطبيعية pay: هي مكتبة مجانية ومفتوحة المصدر لمعالجة ملفات NLP المتقدمة في Python ، وقد تم تصميمها خصيصا للمساعدة في إنشاء التطبيقات التي يمكنها معالجة كميات كبيرة من النصوص وفهمها. ومن المعروف أن Spacy بديهية للغاية ويمكنها التعامل مع العديد من المهام اللازمة في مشاريع معالجة اللغة الطبيعية المشتركة.
            
            باختصار تعتبر معالجة اللغة الطبيعية مجالاً مثيراً من مجالات تطوير الذكاء الاصطناعي التي تغذي مجموعة واسعة من المنتجات الجديدة مثل محركات البحث وروبوتات المحادثة وأنظمة التوصية وأنظمة الكلام إلى النص. مع استمرار الوصلات البشرية مع أجهزة الكمبيوتر في الابتعاد عن الأزرار والنماذج واللغات الخاصة بالمجال ، سيستمر الطلب على النمو في معالجة اللغة الطبيعية في الزيادة. ولهذا السبب، تلتزم Oracle Cloud Infrastructure بتوفير أداء محلي مع أشكال وأدوات الحوسبة المحسنة للأداء من أجل معالجة اللغة الطبيعية. توفر Oracle Cloud Infrastructure صفيقا من أشكال وحدات معالجة الرسومات (GPU) التي يمكنك نشرها في دقائق لبدء التجربة مع NLP.  
            برمجة مراحل معالجة اللغات الطبيعية باستخدام بايثون :-
            
            مكتبات معالجة اللغات الطبيعية في بايثون: Python
            
            بعد هذه المقدمة البسيطة عن معالجة النصوص أن لنا الأوان بعد أن أدركنا مدى حجمه وأهميته وتفرع تطبيقاته أن نبدأ دربنا نحو تعلم استخدامه اخترنا في هذا المقال أن نستخدم المصادر المتاحة في لغة بايثون للمكانة العالية التي تتخذها اللغة حاليًا في مجال الذكاء الصنعي بشكل عالم
            
            تتوافر العديد من المكتبات في بايثون للعمليات المختلفة التي من الممكن القيام بها ضمن مجال معالجة اللغات الطبيعية ومعالجة النصوص، ولكننا في هذا المقال سنتعرف على مكتبتين في مجال معالجة النصوص بالتحديد، حيث أنها تحتوي على العمليات الأساسية لمعالجة النصوص، بالإضافة إلى العمليات الخاصة لنمذجة المواضيع التي سنعود لمناقشتها في المقالات القادمة. 
            
            مجموعة أدوات اللغات الطبيعية: (Natural Language Toolkit (NT
            
            وهي مكتبة مجانية مفتوحة المصدر، تتضمن المهام الأساسية في معالجة اللغات الطبيعية والنصوص من الحصول على الوحدات اللغوية (Tokenization) إلى التجنيع (stemming) وصولا التنبؤ بأقسام الكلام (Part of Speech tagging) الاستنتاج الدلالي (semantic reasoning) وغيرها العديد من المهام اللغوية.
            
            تم تطوير المكتبة في جامعة بنسلفانيا من قبل ستيفن بيرد وإدوارد لوبر، ولعبت دورا كبيرا منذ تطويرها في الأبحاث المتعلقة بمعالجة اللغات الطبيعية، إذ مع امتلاكها واجهة استخدام سهلة وتوفيرها للعديد من المجمعات النصية والمعجمية فقد أصبحت المكتبة التعليمية التي تلجأ لها الجامعات للتدريس والأبحاث، وهي المكان الأنسب ليبدأ أي مهتم في اللغات الطبيعية مسيرته نحو فهم واستخدام مهام معالجة اللغات الطبيعية.
            المكتبة كذلك تتميز بدعمها لعدة لغات تتنوع بحسب المهمة المطلوبة إذ بعض اللغات مدعومة يض المهام وغير مدعومة للبعض الآخر، واللغة العربية من ضمن اللغات المتواجدة في قائمة الدعم لبعض المهام التي سنستعرضها لاحقا في هذا المقال.
            
            التثبيت
            
            pip install –user -U nitk
            
            مو تطلب المكتبة توافر المكتبة العددية لبايثون numpy، لذا في حال عدم توافرها مسبقا على الجهاز يجب تثبيتها:
            
            pip install –user -U numpy
            
            يمكن الاطلاع على الموقع الرسمي للمكتبة من هذا الرابط https://www.altk.org، حيث يتوافر توثيق جيد لها.
            
            مكتبة جينسم Gensim :
            
            وهي مكتبة مجانية مفتوحة المصدر كذلك، تتضمن توابع تساعد على تحديد التشابه الدلالي فيما بين النصوص وتتميز بشكل خاص بفعاليتها العالية مقارنة مع باقي المكتبات المفتوحة في هذا المجال إذ تتحمل معالجة مجمعات نصية بأحجام كبيرة مع إدارة جيدة للذاكرة. مكتبة جينسم Gensim مبنية على أساس خوارزميات نمذجة فضاء المتجهات vector) (pace modeling در خوارزميات نمذجة المواضيع (topic modeling) والتي سنناقشها يتعمق أكبر في المقالات اللاحقة ولكن للتوضيح باختصار فإن كلا النموذجين من الخوارزميات يعتمد مبدأ التعلم بلا إشراف لتحديد التشابه الدلالي فيما بين النصوص وذلك وفق خوارزميات إحصائية. 
            التثبيت
            
            pip install -0 gensim
            
            هذه المكتبة كذلك تتطلب توافر المكتبة العددية لبايثون numpy
            
            يمكن الاطلاع على الموقع الرسمي للمكتبة من هذا الرابط https://radimrehurek.com/gensim/ حيث يتوافر توثيق جيد لها.
            
            المعالجة الأولية النصوص :
            
            مهما كانت المهمة أو المعلومة التي تطمح لاستخلاصها في تطبيقك من الديوان النصي (corpus) بين يديك، فإنك غالبًا ستحتاج لمعالجة هذا النص أولا قبل أن تكون قادرا على تطبيق أي خوارزمية عليه؛ ذلك أن النص الخام يكون عشوائيا بلا أي هيكلية مما لا يسمح للخوارزميات بالتعامل معه، أضف إلى هذا الحجم الهائل له؛ لذا فإن المعالجات الأولية التي تتم على النص تهدف إلى التخفيض من حجمه بالتخلص من الضجيج فيه إضافة إلى خلق هيكلية أولية تمكن الخوارزميات من التعامل معه.
            
            سنناقش في هذا الجزء من الكتاب العمليات الثلاث الأكثر استخداما للمعالجة الأولية، بيد أن بعض الخوارزميات تتطلب معالجات إضافية تتنوع بحسب طبيعة الخوارزمية.
            
            استخلاص الوحدات اللغوية (Tokenization) :-
            
            هذه العملية وكما يقترح الاسم، تقوم بتقطيع النص الذي يكون مخزنا ضمن ذاكرة البرنامج كسلسلة نصية واحدة (String) إلى مصفوفة سلاسل (String Array) ، بكلمات أبسط يتم تقسيم النص إلى كلمات الفاصل بين الكلمات في معظم اللغات هو المسافة، لكنه قد يكون في بعض الأحيان أحرقا أو علامات ترقيم مثلا في اللغات الصينية لا يتم الفصل بين الكلمات على الإطلاق.
            اللغة العربية الفاصل الأساسي ما بين الكلمات هو المسافة مما يجعل المهمة سهلة والمكان الاستعانة بصندوق أدوات اللغات لإتمام هذه المهمة. مرحبا من الذكاء الإصطناعي بالعربية " = sentence tokens =nitk.word_tokenize (sentence)
            
            والنتيجة ستكون بالشكل التالي:
            
            مرحبا "من" " الذكاء الإصطناعي بالعربية "
            
            تلاحظ أن النصوص العربية قد تطلب التخلص من السوابق واللواحق والوصول لأصل الكلمات (Lematization ) في معظم الحالات، وهي بذلك تتمايز عن اللغات اللاتينية مثلا كاللغة الإنكليزية حيث أن السوابق واللواحق العربية ذات أثر أكبر على النص العربي مما هي على النص باللغة الإنجليزية.  
            
            إزالة كلمات الوقف stop words :
            
            كما ذكرنا فإن النص يكون كبيرا ومليئا بالمفردات والكلمات العديدة، ومن الطبيعي أنها ليست كلها بذات القيمة فالكلمات التي تتكرر بشكل كبير ولا تحمل معنى بوجودها وحدها يتم اعتبارها ضجيجا وكلمات وقف يجب إزالتها، فالحروف والأدوات والضمائر في اللغة العربية مثل من، على أن هو هذه ... إلخ، تستخدم بكثرة وهي تشكل ضجيجا في النص ولذا من الأفضل استبعادها، والضجيج غير مقتصر فقط على الحروف والأدوات ففي بعض المجالات. بعض الكلمات تتردد بكثرة مما يحولها إلى كلمات وقف في المجال بحد ذاته وإن كانت في مجال أخر فلم يتم اعتبارها كذلك، فإن كان ديوان النص (corpus) الذي تعمل عليه هو عن الأخبار الرياضية مثلا فإن كلمات : كرة، لاعب ومباراة مثلا ستشكل ضجيجًا إذ أنها على الغالب ستظهر في كل خبر. 
            ولكن دفاتركز على الحالة العامة ونكتفي بالحروف والأدوات حيث سوسا تا صدوق أدوات معالجة اللغات الطبيعية (NETK) بهذا إن أنه يوفر مجموعة كلمات وقف علمة لعدد من اللغات من حملها العربية والانجليزية، ولاستخدامها بإمكانك تطبيق الكود التالي:
            
            from nitk.corpus import stopwords stopwords = set (stopwords.words(arabic))
            
            for w in sentence:
            
            ifw not in stopWords:
            
            filteredSentences.append(w)
            
            والخرج سيكون بالشكل التالي:
            
            أمر حيا" الذكاء الإصطناعي بالعربية "
            
            إنشاء حقيبة الكلمات (bag of words) :
            
            حقيبة الكلمات هي طريقة بسيطة لتمثيل النصوص؛ إذ أنها تتجاهل ترتيب الكلمات والقواعد النحوية، وتركز على تشكيل مصفوفة ذات بعدين يمثل البعد الأول فيها الكلمة بينما يمثل البعد الثاني عدد مرات تكرار هذه الكلمة في مجموعة ( ديوان (corpus النصوص إنشاء حقيبة الكلمات هي مرحلة أساسية في الغالبية العظمى من الخوارزميات الإحصائية في معالجة النصوص، إذ يتم تطبيق الخوارزميات والنماذج الإحصائية عليها.
            
            يمكن الحصول على حقيبة الكلمات بالاستعانة بصندوق أدوات اللغات الطبيعية (NLTK) وكذلك من مكتبة جنسيم (Gensim) وللمثال هذه المرة فلنستخدم الأخيرة. 
            from gensim.corpora import Dictionary dictionary = corpora. Dictionary (filteredSentence)
            
            corpus = Dictionary.doc2bow (filteredSentence)
            
            يقوم النموذج (Dictionary) أولا بإنشاء مصفوفة بكل الكلمات المتمايزة في الجملة، حيث تقابل كل كلمة بدليل، ثم يتم إنشاء حقيبة الكلمات إذ تكون عبارة عن مصفوفة من ثنائيات (pairs) يمثل الحد الأول فيها دليل الكلمة في القاموس (dictionary) أما الحد الثاني فيمثل عدد مرات ظهور هذه الكلمة في الجملة؛ وبالتالي فإننا لجملتنا السابقة ستحصل على الخرج. 
            
            التالي:
            
            [(0, 1), (1, 1), (2,1), (3,1))
            
            وللاطلاع على كلمات القاموس:
            
            print (dictionary.token2id)
            
            والخرج سيكون بالشكل التالي "مرحبا" 0, : الذكاء 1 : ' الإصطناعي 2:;بالعربية 3 :
            
            في البداية سنقوم بتنصيب مكتبتي معالجة النصوص Spacy و textacy على اعتبار أن بايثون ۳ موجود على الجهاز بشكل مسبق.
            
        `,

    },
    {
        "id": 7,
        "type": "lesson",
        "title": "الدرس الثالث",
        "video": "https://res.cloudinary.com/dtxava86t/video/upload/v1683583187/video/lesson7.mp4",
        "sub-title": "عنوان فرعى",
        "desc": `
            Bright and flower, Indicating the beauty of nature and scenic terrain, It Is said that It was named (Sham) relative to Sam bin Noah, peace be upon him. The city of Damascus Is located in the southwestern part of the Syrian Republic, bordering the plains of Horan and the mountains of Qalamoun. The city Is surrounded by orchards of Ghouta, Rabwat Damascus, and Mount Qassioun. The city also overlooks the banks of the Barada River""""

            •	Doc = nlp (text).

            For entity in doc.ents:

            Print (f" (entity.text) ((entity.label_})")

            الخرج على الشكل التالي:
            The Syrian Arab Republic (GPE)

            . Syrian (NORP)

            Damascus (GPE)

            Seventh (ORDINAL)

            Arramad (PERSON)

            Nine thousand years (DATE)

            Damascus (GPE)

            . Assyrian (NORP)

            Sham (PERSON)
            Sam bin Noah (PERSON).

            Damascus (GPE)

            The Syrian Republic (GPE)

            Horan (GPE)

            Qalamoun (GPE).

            Ghouta (GPE) .

            Rabwat Damascus (PERSON)

            Mount Qassioun (PERSON)

            The Barada River (LOC)
            تعتبر GpEعن الكيان الموقع الجغرافي LOC المكان Ordinalالعدد نلاحظ  أن إسناد بعض الكلمات الي  تسميتها كان خاطئا مثل إسناد ربوه دمشق الي Personشخص وجبل قاسيون الي Personشخص .
            اذا كان النص يحتوي على كلمات فريده او مصطلحات مخصصه فلن يكون نموذج التعرف على الكيانات المسماه المبني في مكتبه بايثون SpaCyمدربا علي هذه الكلمات ولذلك لا بد لك من معايرة النموذج ليناسب كلماتك 
            اذا تغيرت القوانين واردنا ان نزيل اسماء الاشخاص فالامر سيكلف الكثير من الوقت اذا تم عمله يدويا لذلك نقوم بازاله هذه الاسماء من خلال معالجه اللغات الطبيعيه من خلال كود البرمجه التالي


            #Replace a token with "REDACTED" if It is a name

            Def replace name with placeholder (token):
            If token.ent_iob != 0 and token.ent_type_ ==

            "PERSON":

            Return "[REDACTED]"

            Else:

            Return token.string
            نفحص في السطر ٣وجود الكيان المسمي PERSON''''شخص " لاستبداله بما يشير إليه 

            "REDACTED“

            #Loop through all the entities in a document and check If they are names

            Def scrub (text):

            Doc= nlp (text)

            For ent in doc.ents:

            Ent.merge()

            Tokens = map(replace_name_with_placeholder,

            Doc)

            Return "" .join(tokens)
            S="""

            In 1950, Alan Turing published his famous article "Computing Machinery and Intelligence". In 1957, Noam Chomsky's
            Syntactic Structures revolutionized Linguistics with 'universal grammar', a rule based system of syntactic structures.

            Print (scrub (s))
            وعند تنفيذ هذا الكود ستكون النتيجه :

            In 1950, [REDACTED] published his famous article "Computing Machinery and Intelligence" in 1957 (REDACTED]

            Syntactic Structures revolutionized Linguistics with 'universal grammar' rule based system of syntactic structures.

        `,
    },
    {
        "id": 8,
        "type": "lesson",
        "title": "الدرس الرابع",
        "video": "https://res.cloudinary.com/dtxava86t/video/upload/v1683583187/video/lesson8.mp4",
        "sub-title": "عنوان فرعى",
        "desc": `
            Fact extractionاستخلاص الحقائق:
            يمكننا استخدام الخرج الناتج من Spacy كدخل الخوارزميات استخلاص البيانات الاكثر تعقيدا فمثلا لدينا مكتبهtextacy التي تنفذ عده خوارزميات استخلاص البيانات منها خوارزميه استخلاص العبارات النصف مهيكله Semi-Structured Statement Extraction  يمكننا استخدامها للبحث في شجره الاعراب الاعتمادي على عبارات بسيطه موضوعها دمشق
            ويجب ان يساعدنا في ذلك العثور على حقائق حول دمشق
            سنطبق الكود البرمجي التالي لتحقيق ذلك:
            import textacy.extract  nlp = spacy.load('en_core_web_sm')  #The text we want to examine  text """Damascus is the capital of the Syrian Arab Republic and the most densely populated Syrian city; Damascus is one of the oldest. inhabited capitals in the world, and historians have suggested that the city's history dates back to before the seventh millennium B.C, Some of the excavations were found in the area of Tall Arramad, and these excavations indicate that the history of the city dates back to nine thousand years BC. The name (Damascus) dates back to ancient Assyrian origins and means the land full of bright and flower, indicating the beauty of nature and scenic terrain, It is said that it was named (Sham) relative to Sam bin Noah, peace be upon him. The city of Damascus is located in the southwestern part of the Syrian Republic, bordering the plains of Horan and the mountains of Qalamoun. The city is surrounded by orchards of Ghouta, Rabwat Damascus, and
            Mount Qassioun. The city also overlooks the banks of the Barada River"""

            # Parse the document with spaCy

            Doc = nlp (text)

            # Extract semi-structured statements

            Statements =

            Textacy.extract.semistructured statements (doc,

            "Damascus")

            # Print the results

            Print("Here are the things I know about

            Damascus: ")

            For statement in statements:

            Subject, verb, fact = statement

            Print (f" (fact)")
            سيكون الخرج كما يلي :
            Here are the things I know about Damascus

            The capital of the Syrian Arab Republic and the most densely populated Syrian city-
            واذا قمنا بتنفيذ نفس الكود على جزء من نص مقاله عن دمشق Damascus"
            فسنحصل على النتيجه التاليه: 
            Here are the things I know about Damascus

            A major cultural center of the Levant and the

            Arab world-

            The center of a large metropolitan area of 2.7

            Million people (2004)
            وللحصول على معلومات أكثر دقة، جرب تشغيل neuralcorer بشكل إضافي حيث أنها تعتمد في عملها على الشبكات العصبية ثم تنفيذ مرحلة القرار الجوهري ضمن تسلسل المعالجة فستحصل على معلومات موجودة في الجمل التي تحتوي على الضمير العائد إلى "دمشق"، وليس فقط المعلومات الموجودة في الجمل التي تحتوي "دمشق" بشكل مباشر
            ماذا يمكن أن نفعل أيضا؟
            من خلال الاطلاع على مستندات spacy ومحررات النصوص، سترى الكثير من الأمثلة على الطرق التي يمكنك من خلالها التعامل مع النصوص التي تم تحليلها. ما رأيناه حتى الآن
            هو مجرد عينة صغيرة.
            إليك مثال عملي أخر تخيل أنك تقوم بإنشاء موقع ويب يتيح للمستخدم عرض المعلومات لكل مدينة في العالم باستخدام المعلومات التي استخرجناها في المثال السابق. إذا كانت لديك ميزة بحث على موقع الويب، فقد يكون من الجيد الإكمال التلقائي لطلبات البحث
            الشائعة مثل Google‏
            ولكن للقيام بذلك، نحتاج إلى قائمة بالإكمالات الممكنة لاقتراحها على المستخدم. يمكننا استخدام
            معالجة اللغات الطبيعية لتوليد هذه البيانات بسرعة
            . فيما يلي طريقه لاستخراج اجزاء الاسماء التي يتم ذكرها بشكل متكرر من مستند:
            Import spacy

            Import textacy.extract

            #Load the large English NLP model

            Nlp = spacy.load('en_core_web_sm')

            # The text we want to examine

            Text="""Damascus Is the capital of the Syrian

            Arab Republic and the most densely populated Syrian city; Damascus is one of the oldest inhabited capitals in the world, and historians have suggested that the city's history cates back to before the seventh millennium B.C,

            Some of the excavations were found in the area

            Of Tall Arramad, and these excavations indicate

            That the history of the city dates back to nine

            Thousand years BC.

            The name (Damascus) dates back to ancient Assyrian origins and means the land full of bright and flower, indicating the beauty of

            Nature and scenic terrain, It is said that it was named (Sham) relative to Sam bin Noah, peace be upon him. The city of
            Damascus is located In the southwestern part of

            The Syrian Republic, bordering the plains of Horan and the mountains of Qalamoun. The city is surrounded by orchards of Ghouta, Rabwat Damascus, and Mount Cassioun. The city also overlooks the banks of the Barada River"" # Parse the document with spacy

            Doc = nlp (text)

            #Extract noun chunks that appear noun chunks = textacy.extract.noun_chunks (doc, min_freg-3)

            # Convert noun chunks to lowercase strings

            Noun_chunks = map(str, noun_chunks) noun_chunks = map(str.lower, noun_chunks)

            # Print out any nouns that are at least 2 words long

            For noun chunk In set (noun_chunks):

            If len (noun_chunk.split(" ")) > 1:

            Print (noun_chunk)
            اذا طبقنا هذا الكود البرمجي على المقطع النص المستخدم فلن نحصل على نتيجه لانه مقطع نصي قصير اذا اخذنا نصا اطول من مقاله ويكيبيديا سيكون الخرج
            Barada river-

            Simple tokenization with .split :-

            As we mentioned before, this is the simplest method to perform tokenization in Python. If you type .split(), the text will be separated at each blank space.

            For this and the following examples, we'll be using a text narrated by Steve Jobs In the "Think Different" Apple commercial.

            Text = """Here's to the crazy ones, the misfits, the rebels, the troublemakers, the round pegs in the square holes. The ones who see things differently they're not fond of rules. You can quote them, disagree with them, glorify or vilify them, but the only thing you can't do Is ignore them because they change things. They push the human race forward, and while some may see them as the crazy ones, we see genius, becausee the ones who are crazy enough to think that they can change the world, are the ones who do."""text.split()

            If we write the code above, we'll obtain the following output.

            ['Here's', 'to', 'the', 'crazy', 'ones, ', 'the',

            'the',

            'misfits,', rebels,, 'the', troublemakers,', 'the', 'round', 'pegs', 'in', 'the', 'square', 'holes.', 'The', 'ones', 'who', 'see', 'things', 'differently', ', 'they' re', 'no', fond', 'of', 'rules.', 'You', 'can', 'quote', 'them, ', 'disagree', 'with', 'them, ', 'glorify', or', 'vilify, 'them, ', 'but', 'the', 'only', 'thing', 'you', 'can't', 'do', 'is', 'ignore', 'change', 'them', 'things.", 'because', 'they', 'They', 'push', 'the', 'human', 'race', 'forward,', 'and', 'some, 'crazy', 'may', 'see', 'ones, ', 'them', 'we', 'see', while', 'as', 'the', 'genius, 'becausee', 'the', 'ones', 'who', 'are', 'crazy', 'enough', 'to', 'think', 'that', 'they', 'can', 'change', 'the', 'world,', 'are', 'the', 'ones', 'who', 'do. '1

            As you can see above, the split() method doesn't consider punctuation symbols as a separate token. This might change your project results
            المراجع 
            R. M. Tong, An operational system for detecting and tracking opinions in on-line discussion, Proceedings of the Workshop on Operational Text Classification (OTC), New Orleans, LO, 2011.

            ⚫ P. Turney, Thumbs up or thumbs down? Semantic orientation applied to unsupervised classification of reviews, Proceedings of the Association for Computational Linguistics (ACL),

            Philadelphia, PA, pp. 417-424, 2012. ⚫ X. Wan, Using bilingual knowledge and ensemble techniquesfor unsupervisedChinese sentiment analysis, Proceedings of EMNIPO8, Honolulu, HI, pp. 553-561, 2018. J.

            ⚫ Wiebe, Learning subjective adjectives from corpora, Proceedings of AAAL, Austin, TX, 2018. J. Wiebe, R. F. Bruce, and T. P. O'Hara, Development and use of a gold standard data set for subjectivity classifications, Proceedings of the Association for Computational Linguistics (ACL), College Park, MD, pp. 246- 253, 2018.

            J. Wiebe and R. Mihalcea, Word sense and subjectivity, Proceedings of the Conference on Computational Linguistics/Association for Computational Linguistics (COLING/ACL), Sydney, Australia, pp. 1065-1072, 2016.

            Wiebe and T. Wilson, Learning to disambiguate potentially subjective expressions, Proceedings of the Conference on Natural

            Language Learning (CoNLL), Taipei, Taiwan, pp. 112-118, 2016.

            J. Wiebe, T. Wilson, and C. Cardie, Annotating expressions of opinions and emotions in language, Language Resources and Evaluation, 1(2), 165-210, 2014.

            ⚫ J. Wiebe, T. Wilson, R. Bruce, M. Bell, and M. Martin, Learning subjective language, Computational Linguistics, 30, 277-308, 2014.

            ⚫ T. Wilson, J. Wiebe, and R. Hwa, Just how mad are you? Finding strong and weak opinion clauses, Proceedings of AAAL, San Jose, CA, pp. 761-769, 2014.

            ⚫ T. Wilson, J. Wiebe, and P. Hoffmann, Recognizing contextual polarity in phrase-level sentiment analysis, Proceedings of the Human Language Technology Conference and the Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), Vancouver, Canada, pp. 347-354, 2015.

            H. Yang, L. Si, and J. Callan, Knowledge transfer and opinion detection in the TREC2016 blog track. Proceedings of TREC, Gaithersburg, MD, 2016.
            ⚫ J. Yi, T. Nasukawa, R. Bunescu, and W. Niblack, Sentiment analyzer: Extracting sentiments about a given topic using natural language processing techniques, Proceedings of the IEEE International Conference on Data Mining (ICDM), Melbourne, FL, 2018.

            H. Yu and V. Hatzivassiloglou, Towards answering opinion questions: Separating facts from opinions and Identifying the polarity of opinion sentences, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), Sapporo, Japan, 2018.


        `,
    },
    {
        "id":9,
        "type": "ques",
        "ques": [
            {
                "id": 0,
                "ques": "هي المرحلة الثامنة من مراحل معالجه النصوص وهي تسمي القرار الجوهري",
                "answer": "هى العلم الذي يجمع بين اللغة وعدد من مجالات علم الحاسب الآلى مثل : تعلم الآلة ، التعلم العميق،الشبكات العصبية الصناعية .",
                "key": ["إجابة", "الأول"],
                "notes": "هي المرحلة الثامنة من مراحل معالجه النصوص وهي تسمي القرار الجوهري"
            },
            {
                "id": 1,
                "ques": "ماهي الاشياء التي تستطيع أنظمة التعرف على الكيانات المسماة تسميتها ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "اسماء الاشخاص/ اسماء الشركات/ المواقع الجغرافية/ اسماء المنتجات/ التاريخ والوقت/ اسماء الأحداث/ كميات النقود"
            },
            {
                "id": 2,
                "ques": "ما الهدف من مرحله الإعراب الاعتمادي ؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "ان الهدف من مرحله الإعراب الاعتمادي هو بناء شجره تعين كلمه أصل واحده لكل كلمه في الجملة وسيكون جذر الشجرة هو الفعل الرئيسي في الجملة"
            },
            {
                "id": 3,
                "ques": "ما هي المرحلة التي تكتشف فيها علاقات كلمات الجملة مع بعض البعض؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "الإعراب الاعتمادي"
            },
            {
                "id": 4,
                "ques": "هل يوجد سلسله قياسيه لحروف التوقف مناسبه لكل التطبيقات ؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "لا يوجد وذلك لأن كلمات التوقف تختلف من تطبيق الي اخر"
            },
            {
                "id": 5,
                "ques": "ما المقصود ب ال  stop words ",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "هي الكلمات التي يجب حذفها من النص قبل البدء بأي عمليه إحصائية ويمكن تحديدها بإضافة سلسلة من الكلمات المعروفة. "
            },
            {
                "id": 6,
                "ques": "قم بشرح المرحلة الرابعة من مراحل معالجه النصوص NLP  ",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "في هذه المرحلة تظهر الكلمة في اللغات الطبيعية بأشكال مختلفة مثل اضافه حرف sمثلا في اللغة الانجليزية للجمع وفي اللغة العربية تضاف أو تحذف حرف في علم الصرف "
            },
            {
                "id": 7,
                "ques": "ماهي مراحل معالجه النصوص ",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "•	الحصول على الوحدات لللغوية "
            },
            {
                "id": 8,
                "ques": "قم بشرح المرحلة الاولى من مراحل معالجه النصوص ",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "ان المرحلة الأولي من مراحل معالجه النصوص وهي عباره عن تقطيع النص الي الجمل المكون منها ومن النص السابق المدروس تكون الجمل وكل جمله من جمل النص يعبر عن فكره معينه كما هو الأمر بالنسبة لأي نص في اللغة الطبيعية "
            },
            {
                "id": 9,
                "ques": "تكلم عن مجموعة أدوات اللغات الطبيعية؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "مكتبة مجانية مفتوحة المصدر تضمن المهام الأساسية في معالجة اللغات الطبيعيه والنصوص من الحصول على الوحدات اللغويه  إلى التجذيع وصولا تنبؤ بأقسام الكلام. والاستنتاج الدلالي وغيرها العديد من المهام اللغوية."
            },
            {
                "id": 10,
                "ques": "ماهى مكتبة جينسـم؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "مكتبة مجانية مفتوحة المصدر تتضمن توابع تساعد على تحديد التشابه الدلالي فيما بين النصوص. تتميز بشكل خاص بفعاليتها العالية مقارنة مع باقي المكتبات المفتوحة ما في هذا المجال تتحمل معالجة مجمعات نصية بأحجام كبيرة مع إدارة جيدة للذاكرة مبنية على أساس خوارزميات نمذجة فضاء المتجهات وخوارزميات نمذجة المواضيع."
            },
            {
                "id": 11,
                "ques": "ماهى استخلاص الوحدات اللغوية؟ ",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "هذه العملية تقوم بتقطيع النص الذي يكون مخزنا ضمن ذاكرة برنامجك سلسلة نصية واحدة إلى مصفوف السلاسل بكلمات أبسط يتم تقسيم النص إلى كلمات الفاصل بين الكلمات في معظم اللغات والمسافة، لكنه قد يكون في بعض الأحيان أحرف أو علامات ترقيم مثل اللغة الصينية لا يتم الفصل بين الكلمات على الإطلاق."
            },
            {
                "id": 12,
                "ques": "ماهى المعالجة الأولية للنصوص؟",
                "answer": "هى العلم الذي يجمع بين اللغة وعدد من مجالات علم الحاسب الآلى مثل : تعلم الآلة ، التعلم العميق،الشبكات العصبية الصناعية .",
                "key": ["إجابة", "الأول"],
                "notes": "مهما كانت المهمة أو المعلومة التي تطمح لاستخلاص ها في تطبيقك من الديوان النصي بين يديك، فإنك غالبا ستحتاج لمعالجة هذا النص أولا قبل أن تكون قادرا على تطبيق أي خوارزمية عليه ذلك أن النص الخام يكون عشوائيا بلا أي هيكلة مما لا يسمح للخوارزميات بالتعامل معه. أضف إلى هذا الحجم الهائل هو.لذا فإن المعالجات الأولية التي تتم على النص تهدف إلى التخفيض من حجمه بالتخلص من الدقيق فيه إضافة إلى خلق هيكلية أولية تمكن الخوارزميات من التعامل معه. "
            },
            {
                "id": 13,
                "ques": "كيف تتم إزالة كلمات التوقف؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "وكما ذكرنا فإن النص قد يكون مليئا بالمفردات والكلمات العديد من الطبيعي أنها ليست كلها بذات القيمة. فالكلمات التي تتكرر بشكل كبير ولا تحمل معنى بوجودها وحدها يتم اعتبارها دقيقا وكلما توقفي يجب إزالتها فالحروف والأدوات والضمائر في اللغة الطبيعية. وذلك مثل مين  أنا. على. هو هذه. تستخدم بكثرة وهي تشكل دقيقا في النص ولذا من الأفضل استبعادها والدقيق غير مقتصر فقط على الحروف والأدوات. ففي بعض المجالات بعض الكلمات تتردد بكثرة مما يحولها إلى كلمات وقف في المجال بحد ذاته وإن كانت في مجال آخر فلم يتم اعتبارها كذلك."
            },
            {
                "id": 14,
                "ques": "كيف يتم إنشاء حقيبه الكلمات؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "هي طريقة بسيطة لتمثيل النصوص إذا أنها تتجاهل ترتيب الكلمات والقواعد النحوية تركز على تشكيل مصفوفة ذات بعدين يمثل البعد الأول في الكلمة بينما  يمثل البعد الثاني عدد مرات تكرار هذه الكلمة. وطعني إنشاء حقيبة هنا أن هي المرحلة أساسية في الغالبية العظمى من الخارج كميات الإحصائية في معالجة النصوص. زي يتم تطبيق الخوارزميات والنماذج الإحصائية عليها ويمكن الحصول على حقيبة الكلمات بالاستعانة بصندوق أدوات اللغات الطبيعية وكذلك في مكتبة جنسم. "
            },
            {
                "id": 15,
                "ques": "ماهى Nlp ؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "في بايسون تتوفر هذه المكاتبات ومجموعات الأدوات بشكل عام في ال بايسون. ولهذا السبب تم تطوير غالبية مشاريع Nlp. في البايسون يسهل بيئة التطوير التفاعلية للبايسون في تطوير التعليمات. البرمجية الجديدة واختيارها.أما عن الجافا والسي بلس بلس. فهنا لمعالجة كميات كبيرة من البيانات غالبا ما يفضل استخدام السي بلس بلس والجبل أنها يمكن أن تدعم تعليمية برمجية أفضل و أكثر كفاءة."
            },
            {
                "id": 16,
                "ques": "ما هي معالجة النصوص؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "فرع من فروع معالجة اللغات الطبيعية ويعنى هذا الفرع بمعالجة اللغة المكتوبة بالذات. يشار إليك ذلك بتنقيب النصوص حيث تتمحور عمليات هذا الفرع من معالجة اللغات الطبيعية على أخذ النص الخام وتحويله إلى شكل يمكن للحاسب فهمه. واستخلاص معلومات منه كبني منطقية أو بيانات هيكلية."
            },
            {
                "id": 17,
                "ques": " مراحل معالجة اللغات الطبيعية؟",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "ملاحظة قبل المتابعه تجدر الاشاره الي ان هذه هي الخطوات في تسلسل معالجة اللغات الطبيعية نموذجية. فقد نتخطى بعض الخطوات أو نعيد ترتيب الخطوات اعتمادا على ما نريد القيام به، وكيفية تنفيذ مكتبات معالجة اللغات الطبيعية. وذلك بعض المكتبات مثل سبيسي. فهي تقوم بتنفيذ تجزئة الجمل بالاعتماد على النتيجة مرحلة الأعراب الاعتماد "
            },
            {
                "id": 18,
                "ques": "عمليات معالجة النصوص تكلم عنها؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "النصوص هي المصدر الوحيد لتخزين المعلومات وتشاركها ومازالت لحد الآن هي كذلك رغم تنوع الكبير في وثائق ممكن استخدامها لنقل المعلومات. المصدر الأساسي لحفظ المعلومات بشتى أنواع إضافة إلى أهميتها. في التواصل مما يجعل عمليات استخلاص المعلومات من النصوص للنهائية بمقدار المعلومات الممكن حفظها فيها، فمن تحديد النصوص المتشابهة إلى تحديد توجه النص إيجابي أو سلبي وصولا إلى التخلص الآلي واستخلاص العناوين وغيرها الكثير."
            },
            {
                "id": 19,
                "ques": "استرجاع المعلومات ماذا تعرف عنها؟",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "يتم فيها استخدام تقنيات معالجة النصوص للبحث والوصول إلى بيانات مكتوبة مثل كلمات أو عبارات أو غيرها من ديوان نص ما على الإنترنت أو دواوين شخصية."
            },
            {
                "id": 20,
                "ques": " التعرف على الإعلام اشرح؟",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "عملية التعرف على الأسماء الإعلام الأشخاص والأماكن والمؤسسات واستخلاصها"
            },
            {
                "id": 21,
                "ques": "تحليل الآراء اشرح؟ ",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "يهدف هذا التحليل لتحديد المعاني الكاملة في النص وليس الحقائق استكشاف المشاعر والتوجه في النص سواء إيجابي أو سلبي أو مهين."
            },
            {
                "id": 22,
                "ques": "كيف تتم عنقده النصـوص",
                "answer": "إجابة السؤال الثالث",
                "key": ["إجابة", "الأول"],
                "notes": "هى عملية التعرف على النصوص المتشابهة وتجميعها معا."
            },
            {
                "id": 23,
                "ques": "ماذا تعرف عن AllenNlp  و Huggingface",
                "answer": "إجابة السؤال الأول",
                "key": ["إجابة", "الأول"],
                "notes": "AllenNlp : هذه مكتبة من مكونات معالجة اللغة الطبيعية عالية المستوى التي يتم تنفيذها في البيسون Huggingface : تقوم هذه الشركة بتوزيع مئات من نماذج معالجة اللغة الطبيعية للتعلم العميق المختلف التي تم تدريبه مسبقا، بالإضافة إلى مجموعة أدوات برامج التوصيل والتشغيل في py Torch تمكن مطورين التقدم السريع لمدى جودة أداء النماذج المختلفة التي تم تدريب عليها"
                
            },
            {
                "id": 24,
                "ques": "ماذا تعرفي عن مكتبة Spacy ؟ ",
                "answer": "إجابة السؤال الثاني",
                "key": ["إجابة", "الأول"],
                "notes": "مكتبة مجانية ومفتوح للمصدر لمعالجة ملفات إن إللي بي المتقدمة في ال بايسون وقد تم تصميمها خصيصا للمساعدة في إنشاء التطبيقات التي يمكن معالجة كميات كبيرة من النصوص وفهمها. ومن المعروف أن السبايسي باتيه للغاية ويمكن التعامل مع العديد من المهام اللازمة في مشاريع معالجة اللغة الطبيعية مشتركة"
            },
        ],
    },
]
